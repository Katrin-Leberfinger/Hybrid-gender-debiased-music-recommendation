{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Katrin-Leberfinger/Hybrid-gender-debiased-music-recommendation/blob/main/models_using_lfm2b_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkBFbi9YA_ys"
      },
      "source": [
        "# BERT for text embedding\n",
        "\n",
        "Code Source:\n",
        "https://gist.github.com/shubhamagarwal92/37ccb747f7130a35a8e76aa66d60e014\n",
        "\n",
        "Interesting articles\n",
        "https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#31-running-bert-on-our-text\n",
        "https://www.kaggle.com/hassanamin/bert-pytorch-cola-classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWHMmzSHaV4j",
        "outputId": "a394f220-4ca5-4492-da0c-775e762664e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L9D-5zOmltBw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from transformers import BertConfig, BertPreTrainedModel, BertModel, BertForSequenceClassification\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertModel, AdamW\n",
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "from sklearn.metrics import f1_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXEH2KDKXjCM"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "4wBsH6CFBrhZ"
      },
      "outputs": [],
      "source": [
        "# data: track_artist -\ttrack_name -\ttrack_tag - track_id\n",
        "\n",
        "def read_items_data_bert(data, id_col, text_col, max_length=512):\n",
        "  tokenizer = BertTokenizer.from_pretrained('prajjwal1/bert-tiny') \n",
        "  #tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') \n",
        "  items = torch.Tensor([])\n",
        "  attentions = torch.Tensor([])\n",
        "  item2pos = dict()\n",
        "  pos2item = dict()\n",
        "  token2id = dict()\n",
        "  num_items = 0\n",
        "  num_tokens = 0\n",
        "  max_item_len = 0\n",
        "\n",
        "  for index, row in data.iterrows():\n",
        "    # for each item:\n",
        "    item_id = row[id_col]\n",
        "    item_words = []\n",
        "    item2pos[item_id] = num_items\n",
        "    pos2item[num_items] = item_id\n",
        "\n",
        "\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        row[text_col], \n",
        "        None,\n",
        "        add_special_tokens=True,\n",
        "        max_length = max_length,\n",
        "        pad_to_max_length=True\n",
        "        \n",
        "    )\n",
        "\n",
        "    tokens = inputs[\"input_ids\"]\n",
        "    attention = inputs['attention_mask']\n",
        "    tokens=torch.tensor(tokens, dtype=torch.long).unsqueeze(0)\n",
        "    attention=torch.tensor(attention, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "    items = torch.concat((items, tokens))\n",
        "    attentions = torch.concat((attentions, attention))\n",
        "    num_items = num_items + 1\n",
        "\n",
        "  return items, attentions, item2pos, pos2item, token2id, max_item_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "MXu90sp8XmdZ"
      },
      "outputs": [],
      "source": [
        "# data: user_id - item_id - rating\n",
        "# playcount: normalize/ binary (>1:1 or <=1:0)\n",
        "\n",
        "def read_ratings_data(data, item2pos, id_col, rating_col, user_col):\n",
        "    ratings = torch.Tensor(len(data), 3)\n",
        "    user2id = dict()\n",
        "    id2user = dict()\n",
        "    num_users = 0\n",
        "    i = 0\n",
        "    for _, row in data.iterrows():\n",
        "        raw_user = row[user_col] \n",
        "\n",
        "        try:\n",
        "          user2id[raw_user]\n",
        "        except:\n",
        "          user2id[raw_user] = num_users\n",
        "          id2user[num_users] = raw_user\n",
        "          num_users = num_users + 1\n",
        "\n",
        "        user = user2id[raw_user]\n",
        "        item = int(item2pos[row[id_col]]) #track_id\n",
        "        rating = int(row[rating_col]) # count\n",
        "\n",
        "        ratings[i][0] = user\n",
        "        ratings[i][1] = item\n",
        "        ratings[i][2] = rating / data[rating_col].max()\n",
        "        i = i+1\n",
        "\n",
        "\n",
        "    return ratings, user2id, id2user\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzTFm7XWXmXv",
        "outputId": "2e702b7a-9676-42fb-fba8-d695f5992fbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWWKtwJxXmQC",
        "outputId": "a82b8dce-4b5d-420e-cc22-971d32caef08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Master Thesis/data\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Master\\ Thesis/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf103qDF0cNv"
      },
      "source": [
        "## Read Data: Lyrics "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lTSGXhgqhfXI"
      },
      "outputs": [],
      "source": [
        "data_tracks_lyrics = pd.read_csv(\"music/data_tracks_lyrics.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "data_tracks_tags_lyrics = pd.read_csv(\"music/data_tracks_tags_lyrics.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "#data_tracks_tags_lyrics=data_tracks_tags_lyrics.iloc[:-1,:]\n",
        "data_interaction = pd.read_csv(\"music/data_user_track_interaction.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)\n",
        "data_user = pd.read_csv(\"music/data_user.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_tracks_lyrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "D7yq3WIEPMNF",
        "outputId": "88ec3b56-56f3-43b1-cb90-8ac3d26b3bf4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1d7aa0b9-80aa-4a34-89f7-e469f683963f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>track_artist</th>\n",
              "      <th>track_name</th>\n",
              "      <th>track_lyrics</th>\n",
              "      <th>lyrics_cleaned</th>\n",
              "      <th>language</th>\n",
              "      <th>track_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>charli xcx</td>\n",
              "      <td>!franchesckaar!</td>\n",
              "      <td>!Franchesckaar!\\nThey all love you\\n!Franchesc...</td>\n",
              "      <td>franchesckaar they all love you franchesckaar...</td>\n",
              "      <td>en</td>\n",
              "      <td>1968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>console</td>\n",
              "      <td>a homeless ghost (wareika's human harmonizer r...</td>\n",
              "      <td>!INCOMPLETE!\\n\\nI was made to defend you\\nFrom...</td>\n",
              "      <td>i was made to defend you from the wrong and t...</td>\n",
              "      <td>en</td>\n",
              "      <td>3260274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tism</td>\n",
              "      <td>!uoy sevol natas</td>\n",
              "      <td>!UOY sevol nataS\\nUoy... uoy... uoy... uoy...\\...</td>\n",
              "      <td>uoy sevol natas uoy uoy uoy uoy mummy she don...</td>\n",
              "      <td>en</td>\n",
              "      <td>2275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>al jarreau</td>\n",
              "      <td>10k hi</td>\n",
              "      <td>\"(Let's try this sound for, for a bit)\\nBoop-b...</td>\n",
              "      <td>boop boo boo boo boop doo doo doo doo doo da ...</td>\n",
              "      <td>en</td>\n",
              "      <td>1787097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>falkenbach</td>\n",
              "      <td>... where blood will soon be shred</td>\n",
              "      <td>\"... From the darkness, risen our of blackness...</td>\n",
              "      <td>from the darkness risen our of blackness a fl...</td>\n",
              "      <td>en</td>\n",
              "      <td>301549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6565</th>\n",
              "      <td>perry como</td>\n",
              "      <td>(did you ever get) that feeling in the moonlight</td>\n",
              "      <td>Did you ever get that feeling in the moonlight...</td>\n",
              "      <td>did you ever get that feeling in the moonlight...</td>\n",
              "      <td>en</td>\n",
              "      <td>176593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6566</th>\n",
              "      <td>the black crowes</td>\n",
              "      <td>a conspiracy (live)</td>\n",
              "      <td>Did you ever hear\\nThe one about last year?\\nI...</td>\n",
              "      <td>did you ever hear the one about last year it w...</td>\n",
              "      <td>en</td>\n",
              "      <td>3192739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6567</th>\n",
              "      <td>samsas traum</td>\n",
              "      <td>5+6=218</td>\n",
              "      <td>Did you ever think about killing yourself?\\n\\n...</td>\n",
              "      <td>did you ever think about killing yourself yes ...</td>\n",
              "      <td>en</td>\n",
              "      <td>2869342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6568</th>\n",
              "      <td>partynextdoor</td>\n",
              "      <td>1942</td>\n",
              "      <td>Did you get my photo?\\nHahaha\\n\\nToo much talk...</td>\n",
              "      <td>did you get my photo hahaha too much talkin ba...</td>\n",
              "      <td>en</td>\n",
              "      <td>2284659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6569</th>\n",
              "      <td>bilmuri</td>\n",
              "      <td>across</td>\n",
              "      <td>Did you call me under fire, just to see how lo...</td>\n",
              "      <td>did you call me under fire just to see how lon...</td>\n",
              "      <td>en</td>\n",
              "      <td>3751175</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6570 rows Ã— 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d7aa0b9-80aa-4a34-89f7-e469f683963f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d7aa0b9-80aa-4a34-89f7-e469f683963f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d7aa0b9-80aa-4a34-89f7-e469f683963f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          track_artist  ... track_id\n",
              "0           charli xcx  ...     1968\n",
              "1              console  ...  3260274\n",
              "2                 tism  ...     2275\n",
              "3           al jarreau  ...  1787097\n",
              "4           falkenbach  ...   301549\n",
              "...                ...  ...      ...\n",
              "6565        perry como  ...   176593\n",
              "6566  the black crowes  ...  3192739\n",
              "6567      samsas traum  ...  2869342\n",
              "6568     partynextdoor  ...  2284659\n",
              "6569           bilmuri  ...  3751175\n",
              "\n",
              "[6570 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = 0\n",
        "i = 0\n",
        "for d in data_tracks_lyrics['lyrics_cleaned']:\n",
        "  l = l+ len(d.split())\n",
        "  i = i+1\n",
        "l/i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPtSd2-TXWHl",
        "outputId": "2530dbdd-9e38-43ff-e89b-450e3185afd1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "284.3041095890411"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_tracks_lyrics['tags'] = data_tracks_lyrics['track_tag']\n",
        "# for index, row in data_tracks_lyrics.iterrows():\n",
        "#   string = ''\n",
        "#   for i in ast.literal_eval(row['track_tag']):\n",
        "#     string = string + i + \",\"\n",
        "#   row['tags'] = string\n",
        "#   data_tracks_lyrics.iloc[index] = row"
      ],
      "metadata": {
        "id": "suOywEk1QhK1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6OhaSF-4unXz"
      },
      "outputs": [],
      "source": [
        "data_interaction.loc[data_interaction['count']<2., 'count'] = 0.\n",
        "data_interaction.loc[data_interaction['count']>=2., 'count'] = 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "i9FIxII88I0k"
      },
      "outputs": [],
      "source": [
        "rating_col = 'count'\n",
        "item_col = 'track_id'\n",
        "user_col = 'user_id'\n",
        "text_col = 'lyrics_cleaned'\n",
        "data_items_eval = data_tracks_lyrics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CV and balance data set"
      ],
      "metadata": {
        "id": "ylBY96MuqFyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_interaction['fold'] = np.random.randint(1, 6, data_interaction.shape[0])\n",
        "\n",
        "import random\n",
        "idx = []\n",
        "for _,df in data_interaction.groupby('fold'):\n",
        "  len_pos = len(df[df[rating_col]==1])\n",
        "  len_neg = len(df[df[rating_col]==0])\n",
        "  if len_pos < len_neg:\n",
        "    df = df[df[rating_col]==0].sample(len_pos).append(df[df[rating_col]==1])\n",
        "  elif len_pos > len_neg:\n",
        "    df = df[df[rating_col]==1].sample(len_pos).append(df[df[rating_col]==0])\n",
        "  idx.extend(df.index.values.tolist())\n",
        "\n",
        "test_fold = 1\n",
        "\n",
        "data_interaction_train = data_interaction.loc[data_interaction.fold != test_fold, [user_col, item_col, rating_col]]\n",
        "data_interaction_test = data_interaction.loc[data_interaction.fold == test_fold, [user_col, item_col, rating_col]]"
      ],
      "metadata": {
        "id": "MR65uPJ6qE9R"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1VnHcVWBFIP"
      },
      "source": [
        "# Ask Me Anything Rating\n",
        "\n",
        "Code source: https://github.com/nlp-deepcbrs/amar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbf_Xg4sE_gu"
      },
      "source": [
        "## **BERT Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrDzG95DcA_8",
        "outputId": "adde8ecd-6122-4743-ce51-3810fea8cd55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "items, attentions, item2pos, pos2item, token2id, max_item_len = read_items_data_bert(data_items_eval, item_col, text_col, 128)\n",
        "ratings_train, user2id_train, id2user_train = read_ratings_data(data_interaction_train, item2pos,  item_col, rating_col, user_col)\n",
        "\n",
        "ratings_test, user2id_test, id2user_test = read_ratings_data(data_interaction_test, item2pos,  item_col, rating_col, user_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "GHWjCxuHb6cX"
      },
      "outputs": [],
      "source": [
        "class AMARBert(nn.Module):\n",
        "    def __init__(self, hidden_dense_layer_size, item_embeddings_size, num_users):\n",
        "        super(AMARBert, self).__init__()\n",
        "        #self.model1_layer2 = BertModel.from_pretrained('prajjwal1/bert-tiny')#('bert-base-uncased')\n",
        "        self.model1_layer2 = BertModel.from_pretrained('prajjwal1/bert-tiny')\n",
        "        self.model1_layer3 = nn.Dropout(p=0.2)\n",
        "\n",
        "        self.model2_layer1 = nn.Embedding(num_users, user_embeddings_size)\n",
        "        \n",
        "        self.linear = nn.Linear(hidden_dense_layer_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        #_, y1 = self.model1_layer2(x[0], attention_mask = x[2],  return_dict=False)\n",
        "        output, y1 = self.model1_layer2(x[0],  return_dict=False)\n",
        "        # y1 = output[:, 0, :]\n",
        "        # pooled_output (=y1) is the output of the CLS token\n",
        "        # \"Since BERT is transformer based contextual model, the idea is [CLS] token would have captured the entire context and would be sufficient for simple downstream tasks such as classification.\"\n",
        "        # https://stackoverflow.com/questions/63673511/how-to-use-the-outputs-of-bert-model?rq=1\n",
        "        # https://towardsdatascience.com/bert-to-the-rescue-17671379687f\n",
        "       # y1 = self.model1_layer3(y1)\n",
        "        \n",
        "        y2 = self.model2_layer1(x[1])\n",
        "\n",
        "        y = torch.cat([y1, y2], 1)\n",
        "        y = self.linear(y)\n",
        "        return self.sigmoid(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJdsCzCuqzHQ",
        "outputId": "caafbc52-f944-4bbd-cc5e-21e3765a30b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Params: items_data, ratings_data, genres_data\n",
        "device = 'cuda'\n",
        "\n",
        "import numpy as np\n",
        "num_examples=ratings_train.size(0)\n",
        "item_embeddings_size = 128\n",
        "user_embeddings_size = 10\n",
        "genre_embeddings_size = 128\n",
        "hidden_dense_layer_size = item_embeddings_size + user_embeddings_size\n",
        "num_users = len(data_interaction[user_col].drop_duplicates())\n",
        "\n",
        "model = AMARBert( hidden_dense_layer_size, item_embeddings_size, num_users)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Vnqy-3XBqQ6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "568765de-d756-4983-a5fd-10b3697cecff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average cost per epoch:  tensor(0.6941, grad_fn=<DivBackward0>)\n",
            "Average cost per epoch:  tensor(0.6932, grad_fn=<DivBackward0>)\n",
            "Average cost per epoch:  tensor(0.6932, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "criterion = nn.BCEWithLogitsLoss() \n",
        "# # https://huggingface.co/transformers/v1.0.0/migration.html\n",
        "lr = 1e-3\n",
        "num_total_steps = 1000\n",
        "num_warmup_steps = 100\n",
        "warmup_proportion = float(num_warmup_steps) / float(num_total_steps)  \n",
        "optimizer = AdamW(model.parameters(), lr=lr, correct_bias=False)  \n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "   optimizer,\n",
        "   num_warmup_steps=num_warmup_steps,\n",
        "   num_training_steps=num_total_steps\n",
        ")\n",
        "\n",
        "\n",
        "num_epochs=3\n",
        "batch_size=256 \n",
        "#batch_size=32\n",
        "num_examples=ratings_train.shape[0]\n",
        "\n",
        "cost_per_epoch = []\n",
        "\n",
        "for e in range(num_epochs):\n",
        "    # shuffle and split training examples in batches\n",
        "    indices = torch.randperm(num_examples).split(batch_size)\n",
        "\n",
        "    #remove last element so that all the batches have equal size\n",
        "    indices = indices[:len(indices)-1] \n",
        "\n",
        "    average_cost = 0\n",
        "\n",
        "    for t, v in enumerate(indices):\n",
        "        #items positions\n",
        "        curr_items_ids_batch = ratings_train[v, 1]\n",
        "\n",
        "        # items descriptions\n",
        "        curr_items_batch = items[curr_items_ids_batch.numpy(),:].to(device)\n",
        "        curr_attentions_batch = attentions[curr_items_ids_batch.numpy(),:].to(device)\n",
        "        \n",
        "        # users ids\n",
        "        curr_users_batch = ratings_train[v, 0].to(device)\n",
        "\n",
        "        # model inputs\n",
        "        inputs = [ curr_items_batch.type(torch.LongTensor), curr_users_batch.type(torch.LongTensor), curr_attentions_batch.type(torch.LongTensor)]\n",
        "\n",
        "        # model targets\n",
        "        targets = ratings_train[v, 2]\n",
        "\n",
        "        # callback that does a single batch optimization step\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # backward propagation\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        \n",
        "        outputs = outputs.reshape(-1,)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        # evaluate current loss function value\n",
        "        average_cost = average_cost + loss\n",
        "        \n",
        "\n",
        "    # evaluate average cost per epoch\n",
        "    average_cost = average_cost / len(indices)\n",
        "    cost_per_epoch.append(average_cost)\n",
        "    print(\"Average cost per epoch: \", average_cost)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGVytV4uSHmc",
        "outputId": "fc01d135-d190-4965-e94a-70789be91359"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0003, grad_fn=<MaxBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTzPCnbSpZX7",
        "outputId": "bb49adf2-6689-44cc-d15b-ae70c814ad68"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0001, grad_fn=<MinBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH1Njid6OwL8"
      },
      "source": [
        "## **BERT**: Get predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feature_vector(model, inputs):\n",
        "\n",
        "  layer = model._modules.get('model1_layer3')\n",
        "\n",
        "  embedding = torch.zeros((1, 128))\n",
        "  def copy_data(m, i, o):\n",
        "          embedding.copy_(o.data)\n",
        "  h = layer.register_forward_hook(copy_data)\n",
        "  model(inputs)\n",
        "  h.remove()\n",
        "  return embedding"
      ],
      "metadata": {
        "id": "KWP35qY4K6vX"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZ3Akda8KGkF"
      },
      "outputs": [],
      "source": [
        "# New version\n",
        "\n",
        "indices = ratings_test[:,0].unique()\n",
        "predictions = {}\n",
        "feature_vectors = {}\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for curr_users_batch in indices:\n",
        "\n",
        "  curr_users_batch = curr_users_batch.to(device).reshape(-1)\n",
        "  indices_items = ratings_test[:,1].unique()\n",
        "  for curr_items_ids_batch in indices_items:\n",
        "    \n",
        "    curr_items_ids_batch = int(curr_items_ids_batch.item())\n",
        "\n",
        "    curr_items_batch = items[curr_items_ids_batch,:].to(device).reshape(1, -1)\n",
        "    \n",
        "    \n",
        "    curr_attentions_batch = attentions[curr_items_ids_batch,:].to(device).reshape(1, -1)\n",
        "\n",
        "    inputs = [ curr_items_batch.type(torch.LongTensor), curr_users_batch.type(torch.LongTensor), curr_attentions_batch.type(torch.LongTensor)]\n",
        "    \n",
        "    targets = model(inputs)\n",
        "    item_list = []\n",
        "\n",
        "    \n",
        "    # save prediction for each user\n",
        "    real_user_id = id2user_test[curr_users_batch[0].item()]\n",
        "    \n",
        "    try:\n",
        "      predictions[real_user_id] \n",
        "    except:\n",
        "      predictions[real_user_id] = []\n",
        "\n",
        "    predictions[real_user_id].append([pos2item[curr_items_ids_batch], \n",
        "                                      targets[0].item()])\n",
        "    \n",
        "    # save embedding layer for each item\n",
        "    feature_vector = get_feature_vector(model, inputs)\n",
        "    try:\n",
        "      feature_vectors[pos2item[curr_items_ids_batch]]\n",
        "    except:\n",
        "      feature_vectors[pos2item[curr_items_ids_batch]] = []\n",
        "    feature_vectors[pos2item[curr_items_ids_batch]].append(feature_vector)\n",
        "        \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "hMJG7-JEzK8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "epmQfDr0Vvzc"
      },
      "outputs": [],
      "source": [
        "topn=10\n",
        "results = []\n",
        "results_df = pd.DataFrame(columns = [user_col, item_col, rating_col])\n",
        "\n",
        "for user in predictions:\n",
        "    item_list = []\n",
        "    user_prediction = predictions[user]\n",
        "\n",
        "    user_prediction = sorted(user_prediction,key=lambda x: (x[1]), reverse=True)\n",
        "    n = 1\n",
        "    for item, rating in user_prediction:\n",
        "        if item  not in item_list:\n",
        "          item_list.append(item)\n",
        "          results_df = pd.concat((results_df, pd.DataFrame(data={user_col:[user],item_col:[item],rating_col:[rating]})))\n",
        "          results.append([user, item, rating])\n",
        "          if n >= topn:\n",
        "              break\n",
        "          n = n + 1\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxzLZWaLAhUZ"
      },
      "source": [
        "# Evaluate predictions\n",
        "\n",
        "Scores: F1@10, ndcg, MAP@k"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ndcg_at(predictions, labels, k=10, assume_unique=True):\n",
        "    \"\"\"Compute the normalized discounted cumulative gain at K.\n",
        "    Compute the average NDCG value of all the queries, truncated at ranking\n",
        "    position k. The discounted cumulative gain at position k is computed as:\n",
        "        sum,,i=1,,^k^ (2^{relevance of ''i''th item}^ - 1) / log(i + 1)\n",
        "    and the NDCG is obtained by dividing the DCG value on the ground truth set.\n",
        "    In the current implementation, the relevance value is binary.\n",
        "    If a query has an empty ground truth set, zero will be used as\n",
        "    NDCG together with a warning.\n",
        "    Source: https://gist.github.com/tgsmith61591/d8aa96ac7c74c24b33e4b0cb967ca519\n",
        "    Parameters\n",
        "    ----------\n",
        "    predictions : array-like, shape=(n_predictions,)\n",
        "        The prediction array. The items that were predicted, in descending\n",
        "        order of relevance.\n",
        "    labels : array-like, shape=(n_ratings,)\n",
        "        The labels (positively-rated items).\n",
        "    k : int, optional (default=10)\n",
        "        The rank at which to measure the NDCG.\n",
        "    assume_unique : bool, optional (default=True)\n",
        "        Whether to assume the items in the labels and predictions are each\n",
        "        unique. That is, the same item is not predicted multiple times or\n",
        "        rated multiple times.\n",
        "    Examples\n",
        "    --------\n",
        "    >>> # predictions for 3 users\n",
        "    >>> preds = [[1, 6, 2, 7, 8, 3, 9, 10, 4, 5],\n",
        "    ...          [4, 1, 5, 6, 2, 7, 3, 8, 9, 10],\n",
        "    ...          [1, 2, 3, 4, 5]]\n",
        "    >>> # labels for the 3 users\n",
        "    >>> labels = [[1, 2, 3, 4, 5], [1, 2, 3], []]\n",
        "    >>> ndcg_at(preds, labels, 3)\n",
        "    0.3333333432674408\n",
        "    >>> ndcg_at(preds, labels, 10)\n",
        "    0.48791273434956867\n",
        "    References\n",
        "    ----------\n",
        "    .. [1] K. Jarvelin and J. Kekalainen, \"IR evaluation methods for\n",
        "           retrieving highly relevant documents.\"\n",
        "    \"\"\"\n",
        "\n",
        "    def _inner_ndcg(pred, lab):\n",
        "        # if we do NOT assume uniqueness, the set is a bit different here\n",
        "        if not assume_unique:\n",
        "            lab = np.unique(lab)\n",
        "\n",
        "        n_lab = lab.shape[0]\n",
        "        n_pred = pred.shape[0]\n",
        "        n = min(max(n_pred, n_lab), k)  # min(min(p, l), k)?\n",
        "\n",
        "        # similar to mean_avg_prcsn, we need an arange, but this time +2\n",
        "        # since python is zero-indexed, and the denom typically needs +1.\n",
        "        # Also need the log base2...\n",
        "        arange = np.arange(n, dtype=np.float32)  # length n\n",
        "\n",
        "        # since we are only interested in the arange up to n_pred, truncate\n",
        "        # if necessary\n",
        "        arange = arange[:n_pred]\n",
        "        denom = np.log2(arange + 2.)  # length n\n",
        "        gains = 1. / denom  # length n\n",
        "\n",
        "        # compute the gains where the prediction is present in the labels\n",
        "        dcg_mask = np.in1d(pred[:n], lab, assume_unique=assume_unique)\n",
        "        dcg = gains[dcg_mask].sum()\n",
        "\n",
        "        # the max DCG is sum of gains where the index < the label set size\n",
        "        max_dcg = gains[arange < n_lab].sum()\n",
        "        return dcg / max_dcg\n",
        "\n",
        "\n",
        "    return _inner_ndcg(predictions, labels)"
      ],
      "metadata": {
        "id": "81X0D6wvfHKD"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def ndcg(rel_true, rel_pred, p=None):\n",
        "    rel_true = np.sort(rel_true)[::-1]\n",
        "    p = min(len(rel_true), min(len(rel_pred), p))\n",
        "    discount = 1 / (np.log2(np.arange(p) + 2))\n",
        "\n",
        "    idcg = np.sum(rel_true[:p] * discount)\n",
        "    dcg = np.sum(rel_pred[:p] * discount)\n",
        "    \n",
        "    return dcg / idcg\n",
        "\n",
        "\n",
        "song_index = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}\n",
        "user_lists = [\"USER1\", \"USER2\", \"USER3\"]\n",
        "\n",
        "relevance_true = {\n",
        "    \"USER1\": [3, 3, 2, 2, 1, 1, 0, 0, 0],\n",
        "    \"USER2\": [3, 2, 1, 1, 2, 0, 1, 1, 1],\n",
        "    \"USER3\": [0, 1, 0, 1, 2, 3, 3, 1, 0]\n",
        "}\n",
        "\n",
        "user = user_lists[0]\n",
        "r_true = relevance_true[user]\n",
        "\n",
        "s1_pred = [r_true[song_index[song]] for song in s1_prediction[user]]\n",
        "\n",
        "print(f'S1 nDCG@5 (linear): {ndcg(r_true, s1_pred, 5)}')\n",
        "print(f'S2 nDCG@5 (linear): {ndcg(true_relevance.tolist()[0], scores.tolist()[0], 6)}')\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iv8LOOpdhY0y",
        "outputId": "050f1a8e-a1c2-49dc-a5f7-d8b1a5014ab3"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S1 nDCG@5 (linear): 0.8232936061974518\n",
            "S2 nDCG@5 (linear): 0.785002371969948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DTstEsi72xS"
      },
      "outputs": [],
      "source": [
        "scores = []\n",
        "for user, df in results_df.groupby(user_col):\n",
        "  df = df.drop_duplicates(subset=item_col)\n",
        "  y_true_sorted = data_interaction_test.loc[data_interaction_test[user_col] == user].sort_values(rating_col, ascending=False)\n",
        "  y_true_df = pd.merge(data_items_eval[[item_col]], y_true_sorted[[item_col, rating_col]], 'left').fillna(0)\n",
        "  y_true_ndcg = y_true_df[rating_col].values\n",
        "  y_true_df.loc[y_true_df[rating_col] > 0, rating_col] = 1\n",
        "  y_true = y_true_df[rating_col].values\n",
        "\n",
        "  y_pred_df = pd.merge(data_items_eval[[item_col]], df[[item_col, rating_col]], 'left').fillna(0)\n",
        "  y_pred_ndcg = y_pred_df[rating_col].values\n",
        "  y_pred_df.loc[y_pred_df[rating_col] > 0, rating_col] = 1\n",
        "  y_pred = y_pred_df[rating_col].values\n",
        "\n",
        "  if y_true.sum() >= 1:\n",
        "    score = f1_score(y_true, y_pred)\n",
        "    scores.append(score)\n",
        "\n",
        "print(\"F1 Score: \", np.mean(scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaONzUp8rsKH"
      },
      "source": [
        "# Interpretability of Bias\n",
        "\n",
        "- Find correlations between user gender and item gender (Pearsons correlation)\n",
        "- For each track get proportion of female/male user => compare train and recommendataion data\n",
        "- Check if genderness increased/decreased in recommendations (in comparision to training data) \n",
        "- Compare distribution of genderness between history and recommendations \n",
        "  - \"Delta Metric of Genderness\" (https://arxiv.org/pdf/2108.06973.pdf)\n",
        "  - Proportion tests: Fisher exact test, Chi-Square\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLkaN3VRONj6"
      },
      "outputs": [],
      "source": [
        "data_artists = pd.read_csv(\"data_artists.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "data_artists.columns = ['track_artist', 'type', 'gender_artist']\n",
        "data_user_track_interaction = pd.read_csv(\"data_user_track_interaction.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)\n",
        "data_user = pd.read_csv(\"data_user.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)\n",
        "data_user.columns = ['user_id', 'gender_user']\n",
        "\n",
        "a = []\n",
        "for i in  data_artists.track_artist.values:\n",
        "  a.append(i.lower())\n",
        "data_artists['track_artist'] = a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dewGb1xmPBXN"
      },
      "outputs": [],
      "source": [
        "df_tmp = pd.merge(data_user_track_interaction, data_user, 'inner')\n",
        "df_all = pd.merge(df_tmp, data_artists, on = 'track_artist').drop_duplicates()\n",
        "df_all = df_all.loc[(df_all['gender_artist'] != 'Unknown') & (df_all['gender_artist'] != 'other')]\n",
        "\n",
        "replace_dict1 = {'m' : 0, 'f' : 1}\n",
        "replace_dict2 = {'male' : 0, 'female' : 1}\n",
        "df_all['gender_user'] = df_all['gender_user'].replace(replace_dict1)\n",
        "df_all['gender_artist'] = df_all['gender_artist'].replace(replace_dict2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgDbgyUFYVPF"
      },
      "source": [
        "## Correlation between user and item gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4aOub4YUaga",
        "outputId": "1f0213c6-3027-44c5-e687-ff66dcc2ee80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In the history data, all female users listen to 8.3 % female itmes.\n",
            "In the history data, all male users listen to 2.67 % female itmes.\n",
            "The attributes gender_user and gender_artist show a correlation of  0.10665398232086548\n"
          ]
        }
      ],
      "source": [
        "# Proportion of female items in all female user\n",
        "prop_female = 0\n",
        "# Proportion of female items in all male user\n",
        "prop_male = 0\n",
        "for group, df in df_all.groupby('gender_user'):\n",
        "  if group == 0:\n",
        "    prop_male = df.gender_artist.sum() / len(df)\n",
        "  else:\n",
        "    prop_female = df.gender_artist.sum() / len(df)\n",
        "\n",
        "print(f'In the history data, all female users listen to {round(prop_female*100, 2)} % female itmes.')\n",
        "print(f'In the history data, all male users listen to {round(prop_male*100, 2)} % female itmes.')\n",
        "\n",
        "# Pearson correlation\n",
        "print('The attributes gender_user and gender_artist show a correlation of ', df_all.gender_user.corr(df_all.gender_artist))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_7r-GujbVZV",
        "outputId": "ca6a1922-b142-4ad9-ad24-e03caec1b036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1905224050321245e-05\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import fisher_exact\n",
        "tab = pd.crosstab(df_all.gender_user, df_all.gender_artist)\n",
        "stats, p_value = fisher_exact(tab)\n",
        "print(p_value)\n",
        "# if p-value <= 0.05 => gender_user and gender_artist are independent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEiaFN1bYdFE"
      },
      "source": [
        "## Delta metric of genderness\n",
        "\n",
        " For user u_i: (prop_female(rec) - prop_female(history)) / prop_female(history)\n",
        "\n",
        " If positive: more female tracks are recommended to the user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYomuJrr3Qj_"
      },
      "outputs": [],
      "source": [
        "df_tmp = pd.merge(results_df, data_user, 'inner')\n",
        "df_artists_tmp = pd.merge(df_tmp, data_user_track_interaction[['track_artist', 'track_id']])\n",
        "df_rec = pd.merge(df_artists_tmp, data_artists, on = 'track_artist').drop_duplicates()\n",
        "df_rec = df_rec.loc[(df_rec['gender_artist'] != 'Unknown') & (df_rec['gender_artist'] != 'other')]\n",
        "df_rec['gender_user'] = df_rec['gender_user'].replace(replace_dict1)\n",
        "df_rec['gender_artist'] = df_rec['gender_artist'].replace(replace_dict2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP_j3yQgd6Gx",
        "outputId": "75eedc37-c1a0-42de-adc8-50b810d53992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The value of delta is -1.0 and therefore more male tracks are recommended to user.\n"
          ]
        }
      ],
      "source": [
        "prop_female_rec = df_rec.gender_artist.sum()\n",
        "prop_female_history = df_all.gender_artist.sum()\n",
        "delta = (prop_female_rec - prop_female_history) / prop_female_history\n",
        "\n",
        "if delta > 0:\n",
        "  print(f'The value of delta is {delta} and therefore more female tracks are recommended to user.')\n",
        "else:\n",
        "  print(f'The value of delta is {delta} and therefore more male tracks are recommended to user.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W5yg61kZJOV"
      },
      "source": [
        "## Proportion test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IV5pBGTjYfsO"
      },
      "outputs": [],
      "source": [
        "# Fisher exact test\n",
        "\n",
        "from scipy.stats import fisher_exact\n",
        "tab = pd.crosstab(df_rec.gender_artist, df_all.gender_artist)\n",
        "stats, p_value = fisher_exact(tab)\n",
        "if p_value <= 0.05:\n",
        "  print(f'The attributes gender_artist of the history and recommendation data are significantly independent.')\n",
        "\n",
        "# if p-value <= 0.05 => gender_x and gender_y are independent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-aNSsd8cv6h",
        "outputId": "ed283829-2b4d-4865-f136-f4f439900c17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/stats/proportion.py:824: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  prop = count * 1. / nobs\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/stats/proportion.py:840: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  nobs_fact = np.sum(1. / nobs)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/stats/weightstats.py:671: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  zstat = value / std_diff\n"
          ]
        }
      ],
      "source": [
        "# z-test\n",
        "\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "significance = 0.005\n",
        "sample_size_hist = df_all.gender_artist.count()\n",
        "sample_success_hist = df_all.gender_artist.sum()\n",
        "sample_success_rec = df_rec.gender_artist.count()\n",
        "sample_size_rec = df_rec.gender_artist.sum()\n",
        "successes = np.array([sample_success_hist, sample_success_rec])\n",
        "samples = np.array([sample_size_hist, sample_size_rec])\n",
        "stat, p_value = proportions_ztest(count=successes, nobs=samples,  alternative='two-sided')\n",
        "if p_value <= 0.05:\n",
        "  print(f'The proportions of gender_artist of the history and recommendation data are significantly different.')\n",
        "# if p-value <= 0.05 => the proportions are significantly different"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict artist gender"
      ],
      "metadata": {
        "id": "NtIQzQEH2vhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "o_NzF7QQ3J6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_all_info = pd.read_csv(\"music/data_all_info.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "data_all_info = data_all_info.loc[data_all_info.artist_gender != 'other' ]"
      ],
      "metadata": {
        "id": "FducXCFxKURy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = feature_vectors"
      ],
      "metadata": {
        "id": "8XV1iDFGB0mF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features = pd.DataFrame()\n",
        "id_col = []\n",
        "\n",
        "for id in data_interaction_test[item_col].unique():\n",
        "  id_col.append(id)\n",
        "  df_features = df_features.append(pd.DataFrame(input[id][0].detach().numpy()))\n",
        "\n",
        "df_features[item_col] = id_col"
      ],
      "metadata": {
        "id": "Zv1QvFM3I22n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features = pd.merge(df_features, data_all_info)"
      ],
      "metadata": {
        "id": "EBOE0G_TJ28n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features.loc[df_features.artist_gender == 'female', 'artist_gender'] = 0\n",
        "df_features.loc[df_features.artist_gender == 'male', 'artist_gender'] = 1\n",
        "df_features.artist_gender = df_features.artist_gender.astype('int')"
      ],
      "metadata": {
        "id": "YOQ6VKT_IVyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_features.iloc[:,:128]\n",
        "y = df_features.artist_gender\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.4, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "2ic2xa382unN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred=clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test.values, y_pred))\n",
        "print(\"Balanced Accuracy:\", metrics.balanced_accuracy_score(y_test.values, y_pred))\n",
        "print(\"Recall: \", metrics.recall_score(y_test.values, y_pred))\n",
        "print(\"Precision: \", metrics.precision_score(y_test.values, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h50TBcLs3G7l",
        "outputId": "6a0f5c73-0cde-43ab-f254-0c7429c0e2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7887323943661971\n",
            "Balanced Accuracy: 0.7465686274509804\n",
            "Recall:  0.8431372549019608\n",
            "Precision:  0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "feature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\n",
        "feature_imp.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQSgoDfe4Cc4",
        "outputId": "d28f5393-a801-4ce2-bd4a-a85e55df7656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104    0.226804\n",
              "98     0.140306\n",
              "17     0.131687\n",
              "81     0.114796\n",
              "127    0.111745\n",
              "62     0.091315\n",
              "5      0.083488\n",
              "111    0.051955\n",
              "3      0.047903\n",
              "69     0.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d-l5O-0D2dm"
      },
      "source": [
        "---------------------------\n",
        "\n",
        "# Next steps\n",
        "\n",
        "[x] Train test split \n",
        "\n",
        "[x] Implement CV\n",
        "\n",
        "[x] Balance data set (use as many listened as unlistened tracks - randomly chosing them)\n",
        "\n",
        "[x] Use Popularity model as baseline\n",
        "\n",
        "[x] Check index behaviour!!! (pos2item,...)\n",
        "\n",
        "[x] Test/train split (https://colab.research.google.com/github/d2l-ai/d2l-en-colab/blob/master/chapter_recommender-systems/movielens.ipynb)\n",
        "\n",
        "[x] Verify BERT Tokenizer\n",
        "\n",
        "[x] Verify data reading with new movie data\n",
        "\n",
        "[x] Try out gender interpretability\n",
        "\n",
        "[ ] Add tags data (instead of lyrics)\n",
        "\n",
        "[x] Get more data\n",
        "\n",
        "[x] Clean lyrics data (remove non-english ones and repeated parts)\n",
        "\n",
        "[x] Use embedding of model to predict gender of artist\n",
        "\n",
        "[x] Try to find song writer gender (not priority) => tried this out but could not find a general solution\n",
        "\n",
        "[ ] Implement ndcg (https://github.com/Jenniferz28/Collaborative-Filtering-Recommendation/blob/69a2400736a628de34620318abe861cc9a19e621/ndcg.py#L77)\n",
        "\n",
        "[ ] Clean up code and move to repository\n",
        "\n",
        "[ ] Implement evaluation with using all items in dataset\n",
        "\n",
        "[ ] BERT make sure this is correct!\n",
        "\n",
        "[ ] Try out correlation interpretability things (e.g. \"Exploring Artist Gender Bias in Music Recommendation\"\n",
        "\n",
        "[ ] Remove 'important' feature vector from recommendataion model and compare recommendation performance + prediction perforamcne\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "UaONzUp8rsKH",
        "hgDbgyUFYVPF",
        "UEiaFN1bYdFE",
        "_W5yg61kZJOV"
      ],
      "machine_shape": "hm",
      "name": "MasterThesis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNA54QHlrunPFRyDXEO0+Si",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}