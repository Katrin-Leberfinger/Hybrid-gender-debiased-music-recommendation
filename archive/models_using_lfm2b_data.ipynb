{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Katrin-Leberfinger/Hybrid-gender-debiased-music-recommendation/blob/main/models_using_lfm2b_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkBFbi9YA_ys"
      },
      "source": [
        "# BERT for text embedding\n",
        "\n",
        "Code Source:\n",
        "https://gist.github.com/shubhamagarwal92/37ccb747f7130a35a8e76aa66d60e014\n",
        "\n",
        "Interesting articles\n",
        "https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#31-running-bert-on-our-text\n",
        "https://www.kaggle.com/hassanamin/bert-pytorch-cola-classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWHMmzSHaV4j",
        "outputId": "cbd707ef-0711-4afb-feba-f045ab6ad283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 14.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 86.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 67.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L9D-5zOmltBw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from transformers import BertConfig, BertPreTrainedModel, BertModel, BertForSequenceClassification\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertModel, AdamW\n",
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXEH2KDKXjCM"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4wBsH6CFBrhZ"
      },
      "outputs": [],
      "source": [
        "# data: track_artist -\ttrack_name -\ttrack_tag - track_id\n",
        "\n",
        "def read_items_data_bert(data, id_col, text_col, max_length=512):\n",
        "  tokenizer = BertTokenizer.from_pretrained('prajjwal1/bert-tiny') \n",
        "  #tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') \n",
        "  items = torch.Tensor([])\n",
        "  attentions = torch.Tensor([])\n",
        "  item2pos = dict()\n",
        "  pos2item = dict()\n",
        "  token2id = dict()\n",
        "  num_items = 0\n",
        "  num_tokens = 0\n",
        "  max_item_len = 0\n",
        "\n",
        "  for index, row in data.iterrows():\n",
        "    # for each item:\n",
        "    item_id = row[id_col]\n",
        "    item_words = []\n",
        "    item2pos[item_id] = num_items\n",
        "    pos2item[num_items] = item_id\n",
        "\n",
        "\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        row[text_col], \n",
        "        None,\n",
        "        add_special_tokens=True,\n",
        "        max_length = max_length,\n",
        "        pad_to_max_length=True\n",
        "        \n",
        "    )\n",
        "\n",
        "    tokens = inputs[\"input_ids\"]\n",
        "    attention = inputs['attention_mask']\n",
        "    tokens=torch.tensor(tokens, dtype=torch.long).unsqueeze(0)\n",
        "    attention=torch.tensor(attention, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "    items = torch.concat((items, tokens))\n",
        "    attentions = torch.concat((attentions, attention))\n",
        "    num_items = num_items + 1\n",
        "\n",
        "  return items, attentions, item2pos, pos2item, token2id, max_item_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MXu90sp8XmdZ"
      },
      "outputs": [],
      "source": [
        "# data: user_id - item_id - rating\n",
        "\n",
        "def read_ratings_data(data, item2pos, id_col, rating_col, user_col):\n",
        "    ratings = torch.Tensor(len(data), 3)\n",
        "    user2id = dict()\n",
        "    id2user = dict()\n",
        "    num_users = 0\n",
        "    i = 0\n",
        "    for _, row in data.iterrows():\n",
        "        raw_user = row[user_col] \n",
        "\n",
        "        try:\n",
        "          user2id[raw_user]\n",
        "        except:\n",
        "          user2id[raw_user] = num_users\n",
        "          id2user[num_users] = raw_user\n",
        "          num_users = num_users + 1\n",
        "\n",
        "        user = user2id[raw_user]\n",
        "        item = int(item2pos[row[id_col]]) #track_id\n",
        "        rating = int(row[rating_col]) # count\n",
        "\n",
        "        ratings[i][0] = user\n",
        "        ratings[i][1] = item\n",
        "        ratings[i][2] = rating / data[rating_col].max()\n",
        "        i = i+1\n",
        "\n",
        "\n",
        "    return ratings, user2id, id2user\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzTFm7XWXmXv",
        "outputId": "792cb6a1-23ee-4226-dca0-07041a6d718a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWWKtwJxXmQC",
        "outputId": "05564b16-0f2d-4884-d554-905df5bc3b01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Master Thesis/data\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Master\\ Thesis/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf103qDF0cNv"
      },
      "source": [
        "## Read Data: Lyrics "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "lTSGXhgqhfXI"
      },
      "outputs": [],
      "source": [
        "data_tracks_lyrics = pd.read_csv(\"music/data_tracks_lyrics.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "data_tracks_tags_lyrics = pd.read_csv(\"music/data_tracks_tags_lyrics.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "data_bio = pd.read_csv(\"music/data_artists_biography.txt\", sep=\",\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "data_interaction = pd.read_csv(\"music/data_user_track_interaction.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)\n",
        "\n",
        "data_tracks_tags_lyrics = data_tracks_tags_lyrics.merge(data_bio)\n",
        "data_interaction = data_interaction.merge(data_tracks_tags_lyrics[['track_id']].drop_duplicates())\n",
        "\n",
        "data_user = pd.read_csv(\"music/data_user.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filter out playcount 1\n",
        "data_interaction = data_interaction[data_interaction['count'] != 1]"
      ],
      "metadata": {
        "id": "ZLT9a8oHXhwr"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "selected_user = random.sample(list(data_interaction.user_id.unique()), 800)\n",
        "selected_items = random.sample(list(data_interaction.track_id.unique()), 1000)\n",
        "data_interaction = data_interaction.loc[(data_interaction.user_id.isin(selected_user)) & (data_interaction.track_id.isin(selected_items))]"
      ],
      "metadata": {
        "id": "D7yq3WIEPMNF"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "6OhaSF-4unXz"
      },
      "outputs": [],
      "source": [
        "data_interaction.loc[data_interaction['count']<2., 'count'] = 0.\n",
        "data_interaction.loc[data_interaction['count']>=2., 'count'] = 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "i9FIxII88I0k"
      },
      "outputs": [],
      "source": [
        "rating_col = 'count'\n",
        "item_col = 'track_id'\n",
        "user_col = 'user_id'\n",
        "text_col = 'tags'\n",
        "data_items_eval = data_tracks_tags_lyrics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CV and balance data set"
      ],
      "metadata": {
        "id": "ylBY96MuqFyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_interaction['fold'] = np.random.randint(1, 6, data_interaction.shape[0])\n",
        "\n",
        "import random\n",
        "idx = []\n",
        "for _,df in data_interaction.groupby('fold'):\n",
        "  len_pos = len(df[df[rating_col]==1])\n",
        "  len_neg = len(df[df[rating_col]==0])\n",
        "  if len_pos < len_neg:\n",
        "    df = df[df[rating_col]==0].sample(len_pos).append(df[df[rating_col]==1])\n",
        "  elif len_pos > len_neg:\n",
        "    df = df[df[rating_col]==1].sample(len_pos).append(df[df[rating_col]==0])\n",
        "  idx.extend(df.index.values.tolist())"
      ],
      "metadata": {
        "id": "K80IBML0Y1Io"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove user with too little playcount\n",
        "# add negative samples\n",
        "data_interaction_new = pd.DataFrame(columns = data_interaction.columns)\n",
        "for user_id,df in data_interaction.groupby('user_id'):\n",
        "  if len(df) >= 10:\n",
        "    df_tmp = df.merge(data_items_eval[['track_id']], how = 'right')\n",
        "    neg_list = random.sample(list(df_tmp[np.isnan(df_tmp.user_id)].track_id.values), len(df))\n",
        "    df_neg = pd.DataFrame({'user_id': user_id, 'track_id':neg_list, 'count':0})\n",
        "    data_interaction_new=data_interaction_new.append(df)\n",
        "    data_interaction_new=data_interaction_new.append(df_neg)\n",
        "data_interaction_new = shuffle(data_interaction_new)"
      ],
      "metadata": {
        "id": "fZz3rAP2bCfv"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_interaction_new['fold'] = np.random.randint(1, 6, data_interaction_new.shape[0])\n",
        "\n",
        "test_fold = 1\n",
        "val_fold = 2\n",
        "\n",
        "\n",
        "data_interaction_train = data_interaction_new.loc[((data_interaction_new.fold != test_fold) & (data_interaction_new.fold != val_fold)), [user_col, item_col, rating_col]]\n",
        "data_interaction_test = data_interaction_new.loc[data_interaction_new.fold == test_fold, [user_col, item_col, rating_col]]\n",
        "data_interaction_val = data_interaction_new.loc[data_interaction_new.fold == val_fold, [user_col, item_col, rating_col]]"
      ],
      "metadata": {
        "id": "MR65uPJ6qE9R"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# itermin solution (maybe change later)\n",
        "for user_id,df in data_interaction_test.groupby('user_id'):\n",
        "\n",
        "  df_tmp = df.merge(data_items_eval[['track_id']], how = 'right')\n",
        "  neg_list = list(df_tmp.loc[df_tmp.isna().any(axis=1),].track_id.values)\n",
        "  df_neg = pd.DataFrame({'user_id': user_id, 'track_id':neg_list, 'count':0})\n",
        "  data_interaction_test=data_interaction_test.append(df_neg)\n",
        "data_interaction_test = shuffle(data_interaction_test)\n",
        "data_interaction_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kVsfyhSr7IcO",
        "outputId": "623e357f-d5e9-4239-f376-6efa67b4f86c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     user_id   track_id count\n",
              "1705   35161  3466459.0     0\n",
              "3182   18190  3210124.0     0\n",
              "1733   13676   194963.0     0\n",
              "1951   32196  3471121.0     0\n",
              "1118     561  6094416.0     0\n",
              "...      ...        ...   ...\n",
              "3935    6415  6112759.0     0\n",
              "1156   13676  6205458.0     0\n",
              "4399   18190  3690163.0     0\n",
              "1154     260  4981016.0     0\n",
              "841     1231  6570932.0     0\n",
              "\n",
              "[65365 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c36727b4-6509-48bd-8260-22dfe292b2a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>track_id</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1705</th>\n",
              "      <td>35161</td>\n",
              "      <td>3466459.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3182</th>\n",
              "      <td>18190</td>\n",
              "      <td>3210124.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1733</th>\n",
              "      <td>13676</td>\n",
              "      <td>194963.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1951</th>\n",
              "      <td>32196</td>\n",
              "      <td>3471121.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1118</th>\n",
              "      <td>561</td>\n",
              "      <td>6094416.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3935</th>\n",
              "      <td>6415</td>\n",
              "      <td>6112759.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1156</th>\n",
              "      <td>13676</td>\n",
              "      <td>6205458.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4399</th>\n",
              "      <td>18190</td>\n",
              "      <td>3690163.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1154</th>\n",
              "      <td>260</td>\n",
              "      <td>4981016.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841</th>\n",
              "      <td>1231</td>\n",
              "      <td>6570932.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65365 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c36727b4-6509-48bd-8260-22dfe292b2a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c36727b4-6509-48bd-8260-22dfe292b2a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c36727b4-6509-48bd-8260-22dfe292b2a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1VnHcVWBFIP"
      },
      "source": [
        "# Ask Me Anything Rating\n",
        "\n",
        "Code source: https://github.com/nlp-deepcbrs/amar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbf_Xg4sE_gu"
      },
      "source": [
        "## **BERT Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrDzG95DcA_8",
        "outputId": "c311206f-e3c1-4788-b389-273232f2d4cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "items, attentions, item2pos, pos2item, token2id, max_item_len = read_items_data_bert(data_items_eval, item_col, text_col, 128)\n",
        "\n",
        "\n",
        "ratings_train, user2id_train, id2user_train = read_ratings_data(data_interaction_train, item2pos,  item_col, rating_col, user_col)\n",
        "ratings_test, user2id_test, id2user_test = read_ratings_data(data_interaction_test, item2pos,  item_col, rating_col, user_col)\n",
        "ratings_val, user2id_val, id2user_val = read_ratings_data(data_interaction_val, item2pos,  item_col, rating_col, user_col)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AMARBase(nn.Module):\n",
        "  \"\"\"Model with LT tables for user and items.\"\"\"\n",
        "  def __init__(self, hidden_dense_layer_size, item_embeddings_size, num_users, num_items):\n",
        "      super(AMARBase, self).__init__()\n",
        "\n",
        "      self.model1_layer1 = nn.Embedding(num_items, item_embeddings_size)\n",
        "\n",
        "      self.model2_layer1 = nn.Embedding(num_users, user_embeddings_size)\n",
        "      \n",
        "      self.linear = nn.Linear(hidden_dense_layer_size, 1)\n",
        "      self.sigmoid = nn.Sigmoid()\n",
        "      \n",
        "  def forward(self, x):\n",
        "      y1 = self.model1_layer1(x[0])\n",
        "      \n",
        "      y2 = self.model2_layer1(x[2])\n",
        "\n",
        "      y = torch.cat([y1, y2], 1)\n",
        "      y = self.linear(y)\n",
        "      return self.sigmoid(y)\n"
      ],
      "metadata": {
        "id": "p_Vn354IdSzX"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "GHWjCxuHb6cX"
      },
      "outputs": [],
      "source": [
        "class AMARBert(nn.Module):\n",
        "    def __init__(self, hidden_dense_layer_size, item_embeddings_size, num_users, num_items):\n",
        "        super(AMARBert, self).__init__()\n",
        "        \n",
        "        self.model1_layer2 = BertModel.from_pretrained('prajjwal1/bert-tiny')\n",
        "        self.model1_layer3 = nn.Dropout(p=0.2)\n",
        "\n",
        "        self.model2_layer1 = nn.Embedding(num_users, user_embeddings_size)\n",
        "\n",
        "        self.model3_layer1 = nn.Embedding(num_items, item_embeddings_size)\n",
        "\n",
        "        self.embedding =  nn.Dropout(p=0.2)\n",
        "        \n",
        "        self.linear = nn.Linear(hidden_dense_layer_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        #_, y1 = self.model1_layer2(x[1], attention_mask = x[3],  return_dict=False)\n",
        "        output, y1 = self.model1_layer2(x[1],  return_dict=False)\n",
        "        y1 = output[:, 0, :]\n",
        "        # pooled_output (=y1) is the output of the CLS token\n",
        "        # \"Since BERT is transformer based contextual model, the idea is [CLS] token would have captured the entire context and would be sufficient for simple downstream tasks such as classification.\"\n",
        "        # https://stackoverflow.com/questions/63673511/how-to-use-the-outputs-of-bert-model?rq=1\n",
        "        # https://towardsdatascience.com/bert-to-the-rescue-17671379687f\n",
        "       # y1 = self.model1_layer3(y1)\n",
        "        \n",
        "        y2 = self.model2_layer1(x[2])\n",
        "\n",
        "        y3 = self.model3_layer1(x[0])\n",
        "\n",
        "        y = torch.cat([y1, y2, y3], 1)\n",
        "        y = self.embedding(y)\n",
        "        y = self.linear(y)\n",
        "        return self.sigmoid(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AMARBert2(nn.Module):\n",
        "    def __init__(self, hidden_dense_layer_size, item_embeddings_size, num_users, num_items):\n",
        "        super(AMARBert, self).__init__()\n",
        "        \n",
        "        self.model1_layer1 = BertModel.from_pretrained('prajjwal1/bert-tiny')\n",
        "        self.model1_layer2 = nn.Dropout(p=0.2)\n",
        "\n",
        "\n",
        "        self.model2_layer1 = nn.Embedding(num_users, user_embeddings_size)\n",
        "\n",
        "        self.model3_layer1 = nn.Embedding(num_items, item_embeddings_size)\n",
        "\n",
        "        self.model4_layer2 = BertModel.from_pretrained('prajjwal1/bert-tiny')\n",
        "        self.model4_layer3 = nn.Dropout(p=0.2)\n",
        "\n",
        "        self.embedding =  nn.Dropout(p=0.2)\n",
        "        \n",
        "        self.linear = nn.Linear(hidden_dense_layer_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        #_, y1 = self.model1_layer2(x[1], attention_mask = x[3],  return_dict=False)\n",
        "        output, y1 = self.model1_layer1(x[1],  return_dict=False)\n",
        "        y1 = output[:, 0, :]\n",
        "       # y1 = self.model1_layer2(y1)\n",
        "        \n",
        "        y2 = self.model2_layer1(x[2])\n",
        "\n",
        "        y3 = self.model3_layer1(x[0])\n",
        "\n",
        "        output, y4 = self.model4_layer1(x[1],  return_dict=False)\n",
        "\n",
        "        y = torch.cat([y1, y2, y3, y4], 1)\n",
        "        y = self.embedding(y)\n",
        "        y = self.linear(y)\n",
        "        return self.sigmoid(y)\n"
      ],
      "metadata": {
        "id": "4KP-CPVNaNZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "70491ef249434a5a8de8a33ec18725f3",
            "bb160db681944f44b33492023d8c76d5",
            "d7111bcf87454b1099a2a3162aafefbb",
            "99018ec3488f4f7b82b87d10c77b8ed0",
            "b0a06778441a48d9aa832974be8ab463",
            "c790afb2b79f48f2806a5b26275e5b58",
            "0d2cd84af0494b23a782a7f30a81c2b7",
            "775d440e94f4425196c104fe0d719177",
            "e4794baae2e146a38e050f62aa7de759",
            "c7de23e2a2584c0d9804b9eba9eb842e",
            "f5af5c67acef4d2e99ef38e99e999911"
          ]
        },
        "id": "OJdsCzCuqzHQ",
        "outputId": "b92094cd-4099-48b0-edcd-57ffeedb6325"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/16.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70491ef249434a5a8de8a33ec18725f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Params: items_data, ratings_data, genres_data\n",
        "device = 'cuda'\n",
        "\n",
        "import numpy as np\n",
        "num_examples=ratings_train.size(0)\n",
        "item_text_embeddings_size = 128\n",
        "user_embeddings_size = 50\n",
        "item_embeddings_size = 50\n",
        "\n",
        "\n",
        "num_users = len(data_interaction[user_col].drop_duplicates())\n",
        "num_items = max(max(ratings_train[:, 1]), max(ratings_test[:, 1])).int().item()+1\n",
        "\n",
        "hidden_dense_layer_size_base = item_embeddings_size + user_embeddings_size\n",
        "model_base = AMARBase( hidden_dense_layer_size_base, item_embeddings_size, num_users, num_items)\n",
        "\n",
        "hidden_dense_layer_size_bert = item_embeddings_size + item_text_embeddings_size + user_embeddings_size\n",
        "model_bert = AMARBert( hidden_dense_layer_size_bert, item_embeddings_size, num_users, num_items)\n",
        "\n",
        "model = model_bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Vnqy-3XBqQ6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0c7d6fc-3f4c-41c4-9188-b461fced1cd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average cost per epoch: Train: 0.7242475748062134, Val: 1.4565099477767944\n",
            "Average cost per epoch: Train: 0.7273387908935547, Val: 1.4582102298736572\n",
            "Average cost per epoch: Train: 0.7191010117530823, Val: 1.4498050212860107\n",
            "Average cost per epoch: Train: 0.7117233872413635, Val: 1.4275760650634766\n",
            "Average cost per epoch: Train: 0.6993715763092041, Val: 1.4015315771102905\n",
            "Average cost per epoch: Train: 0.689010739326477, Val: 1.3840696811676025\n",
            "Average cost per epoch: Train: 0.681664228439331, Val: 1.3765108585357666\n",
            "Average cost per epoch: Train: 0.66888827085495, Val: 1.3682613372802734\n",
            "Average cost per epoch: Train: 0.6646625995635986, Val: 1.3659460544586182\n",
            "Average cost per epoch: Train: 0.6545223593711853, Val: 1.3614150285720825\n",
            "Average cost per epoch: Train: 0.6551294326782227, Val: 1.358638048171997\n",
            "Average cost per epoch: Train: 0.6618102192878723, Val: 1.373974084854126\n",
            "Average cost per epoch: Train: 0.6372389793395996, Val: 1.3483710289001465\n",
            "Average cost per epoch: Train: 0.6398805379867554, Val: 1.3582955598831177\n",
            "Average cost per epoch: Train: 0.6365764141082764, Val: 1.3522566556930542\n",
            "Average cost per epoch: Train: 0.6297415494918823, Val: 1.3431332111358643\n",
            "Average cost per epoch: Train: 0.6339385509490967, Val: 1.3430522680282593\n",
            "Average cost per epoch: Train: 0.6248011589050293, Val: 1.331981897354126\n",
            "Average cost per epoch: Train: 0.6272023320198059, Val: 1.3328540325164795\n",
            "Average cost per epoch: Train: 0.6223162412643433, Val: 1.3327176570892334\n",
            "Average cost per epoch: Train: 0.6093235015869141, Val: 1.328298807144165\n",
            "Average cost per epoch: Train: 0.6111345887184143, Val: 1.3245923519134521\n",
            "Average cost per epoch: Train: 0.6015982627868652, Val: 1.3097172975540161\n",
            "Average cost per epoch: Train: 0.5995545983314514, Val: 1.328019380569458\n",
            "Average cost per epoch: Train: 0.6028172969818115, Val: 1.3117566108703613\n",
            "Average cost per epoch: Train: 0.5958244204521179, Val: 1.3180420398712158\n",
            "Average cost per epoch: Train: 0.5895408987998962, Val: 1.3114359378814697\n",
            "Average cost per epoch: Train: 0.5791229009628296, Val: 1.3066387176513672\n",
            "Average cost per epoch: Train: 0.5879169702529907, Val: 1.3384151458740234\n",
            "Average cost per epoch: Train: 0.5845668315887451, Val: 1.3212370872497559\n"
          ]
        }
      ],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "criterion = nn.BCEWithLogitsLoss() \n",
        "# # https://huggingface.co/transformers/v1.0.0/migration.html\n",
        "lr = 1e-3\n",
        "num_total_steps = 1000\n",
        "num_warmup_steps = 100\n",
        "warmup_proportion = float(num_warmup_steps) / float(num_total_steps)  \n",
        "optimizer = AdamW(model.parameters(), lr=lr, correct_bias=False)  \n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "   optimizer,\n",
        "   num_warmup_steps=num_warmup_steps,\n",
        "   num_training_steps=num_total_steps\n",
        ")\n",
        "\n",
        "\n",
        "num_epochs=30\n",
        "batch_size=256 \n",
        "\n",
        "loss_train = []\n",
        "loss_val = []\n",
        "\n",
        "for e in range(num_epochs):\n",
        "    # shuffle and split training examples in batches\n",
        "    indices = torch.randperm(ratings_train.shape[0]).split(batch_size)\n",
        "\n",
        "    #remove last element so that all the batches have equal size\n",
        "    indices = indices[:len(indices)-1] \n",
        "\n",
        "    average_cost = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for t, v in enumerate(indices):\n",
        "        #items positions\n",
        "        curr_items_ids_batch = ratings_train[v, 1]\n",
        "\n",
        "        # items descriptions\n",
        "        curr_items_batch = items[curr_items_ids_batch.numpy(),:].to(device)\n",
        "        curr_attentions_batch = attentions[curr_items_ids_batch.numpy(),:].to(device)\n",
        "        \n",
        "        # users ids\n",
        "        curr_users_batch = ratings_train[v, 0].to(device)\n",
        "\n",
        "        # model inputs\n",
        "        inputs = [curr_items_ids_batch.to(device).type(torch.LongTensor), curr_items_batch.type(torch.LongTensor), curr_users_batch.type(torch.LongTensor), curr_attentions_batch.type(torch.LongTensor)]\n",
        "\n",
        "        # model targets\n",
        "        targets = ratings_train[v, 2]\n",
        "\n",
        "        # callback that does a single batch optimization step\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # backward propagation\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        \n",
        "        outputs = outputs.reshape(-1,)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        # evaluate current loss function value\n",
        "        average_cost = average_cost + loss\n",
        "        \n",
        "    # compute loss on validation set\n",
        "\n",
        "    with torch.no_grad():\n",
        "      indices_val = torch.randperm(ratings_val.shape[0]).split(batch_size)\n",
        "\n",
        "      average_cost_val = 0\n",
        "\n",
        "      for t, v in enumerate(indices_val):\n",
        "              v = v.type(torch.LongTensor)\n",
        "              #items positions\n",
        "              curr_items_ids_batch = ratings_val[v, 1]\n",
        "\n",
        "              # items descriptions\n",
        "              curr_items_batch = items[curr_items_ids_batch.numpy(),:].to(device)\n",
        "              curr_attentions_batch = attentions[curr_items_ids_batch.numpy(),:].to(device)\n",
        "              \n",
        "              # users ids\n",
        "              curr_users_batch = ratings_val[v, 0].to(device)\n",
        "\n",
        "              # model inputs\n",
        "              inputs = [curr_items_ids_batch.to(device).type(torch.LongTensor), curr_items_batch.type(torch.LongTensor), curr_users_batch.type(torch.LongTensor), curr_attentions_batch.type(torch.LongTensor)]\n",
        "\n",
        "              # model targets\n",
        "              targets = ratings_val[v, 2]\n",
        "\n",
        "              # backward propagation\n",
        "              outputs = model(inputs)\n",
        "\n",
        "              outputs = outputs.reshape(-1,)\n",
        "              loss = criterion(outputs, targets)\n",
        "              average_cost_val = average_cost + loss\n",
        "\n",
        "      average_cost_val = average_cost_val / len(indices_val)\n",
        "      loss_val.append(average_cost_val.item())\n",
        "\n",
        "\n",
        "    # evaluate average cost per epoch\n",
        "    average_cost = average_cost / len(indices)\n",
        "    loss_train.append(average_cost.item())\n",
        "    print(f\"Average cost per epoch: Train: {average_cost.item()}, Val: {average_cost_val.item()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_train)\n",
        "plt.plot(loss_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "CfR4uzskpgFt",
        "outputId": "b82b32e8-cfe0-4547-8d0b-1dbf4c0a29c9"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f61a305a7d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH1Njid6OwL8"
      },
      "source": [
        "## **BERT**: Get predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feature_vector(model, inputs, batch_size):\n",
        "\n",
        "  layer = model._modules.get('model1_layer3')\n",
        "\n",
        "  embedding = torch.zeros((batch_size, 128))\n",
        "  def copy_data(m, i, o):\n",
        "          embedding.copy_(o.data)\n",
        "  h = layer.register_forward_hook(copy_data)\n",
        "  model(inputs)\n",
        "  h.remove()\n",
        "  return embedding"
      ],
      "metadata": {
        "id": "KWP35qY4K6vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = {}\n",
        "\n",
        "with torch.no_grad():\n",
        "  indices_test = torch.randperm(ratings_test.shape[0]).split(batch_size)\n",
        "\n",
        "  average_cost = 0\n",
        "\n",
        "  for t, v in enumerate(indices_test):\n",
        "          v = v.type(torch.LongTensor)\n",
        "          #items positions\n",
        "          curr_items_ids_batch = ratings_test[v, 1]\n",
        "\n",
        "          # items descriptions\n",
        "          curr_items_batch = items[curr_items_ids_batch.numpy(),:].to(device)\n",
        "          curr_attentions_batch = attentions[curr_items_ids_batch.numpy(),:].to(device)\n",
        "          \n",
        "          # users ids\n",
        "          curr_users_batch = ratings_test[v, 0].to(device)\n",
        "\n",
        "          # model inputs\n",
        "          inputs = [curr_items_ids_batch.to(device).type(torch.LongTensor), curr_items_batch.type(torch.LongTensor), curr_users_batch.type(torch.LongTensor), curr_attentions_batch.type(torch.LongTensor)]\n",
        "\n",
        "          # model targets\n",
        "          targets = ratings_test[v, 2]\n",
        "\n",
        "          # backward propagation\n",
        "          outputs = model(inputs)\n",
        "\n",
        "          outputs = outputs.reshape(-1,)\n",
        "          loss = criterion(outputs, targets)\n",
        "          average_cost = average_cost + loss\n",
        "\n",
        "          # save prediction for each user\n",
        "          \n",
        "          for i in range(outputs.shape[0]):\n",
        "\n",
        "            real_user_id = id2user_test[curr_users_batch[i].item()]\n",
        "            try:\n",
        "              predictions[real_user_id] \n",
        "            except:\n",
        "              predictions[real_user_id] = []\n",
        "\n",
        "            predictions[real_user_id].append([pos2item[curr_items_ids_batch[i].item()], \n",
        "                                              outputs[i].item()])\n",
        "            \n",
        "  print(f\"Average cost test: {average_cost / len(indices_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCUid5ff91xI",
        "outputId": "2d64e7c2-b397-4e3d-fbb7-5c37f7737211"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average cost test: 0.9357069134712219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZ3Akda8KGkF"
      },
      "outputs": [],
      "source": [
        "# batch_size = 256\n",
        "\n",
        "# indices = ratings_test[:,0].unique()\n",
        "# predictions = {}\n",
        "# feature_vectors = {}\n",
        "\n",
        "# model.eval()\n",
        "\n",
        "# for curr_users_batch in indices:\n",
        "\n",
        "#   curr_users_batch = curr_users_batch.to(device).reshape(-1)\n",
        "#  # curr_users_batch = curr_users_batch.repeat(batch_size)\n",
        "#   indices_items = ratings_test[:,1].unique()#.split(batch_size)[:-1]\n",
        "#   for curr_items_ids_batch in indices_items:\n",
        "    \n",
        "#     curr_items_ids_batch = int(curr_items_ids_batch.item())\n",
        "\n",
        "#     curr_items_batch = items[curr_items_ids_batch,:].to(device).reshape(1, -1)\n",
        "    \n",
        "    \n",
        "#     curr_attentions_batch = attentions[curr_items_ids_batch,:].to(device).reshape(1, -1)\n",
        "\n",
        "#     inputs = [ curr_items_batch.type(torch.LongTensor), curr_users_batch.type(torch.LongTensor), curr_attentions_batch.type(torch.LongTensor)]\n",
        "    \n",
        "#     targets = model(inputs)\n",
        "#     item_list = []\n",
        "    \n",
        "    \n",
        "#     # save prediction for each user\n",
        "#     real_user_id = id2user_test[curr_users_batch[0].item()]\n",
        "\n",
        "#     for i in range(targets.shape[0]):\n",
        "    \n",
        "#       try:\n",
        "#         predictions[real_user_id] \n",
        "#       except:\n",
        "#         predictions[real_user_id] = []\n",
        "\n",
        "#       predictions[real_user_id].append([pos2item[curr_items_ids_batch], \n",
        "#                                         targets[i].item()])\n",
        "    \n",
        "#     # save embedding layer for each item\n",
        "#     feature_vector = get_feature_vector(model, inputs, batch_size)\n",
        "#     try:\n",
        "#       feature_vectors[pos2item[curr_items_ids_batch]]\n",
        "#     except:\n",
        "#       feature_vectors[pos2item[curr_items_ids_batch]] = []\n",
        "#     feature_vectors[pos2item[curr_items_ids_batch]].append(feature_vector)\n",
        "        \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "epmQfDr0Vvzc"
      },
      "outputs": [],
      "source": [
        "topn=10\n",
        "results = []\n",
        "results_df = pd.DataFrame(columns = [user_col, item_col, rating_col])\n",
        "\n",
        "for user in predictions:\n",
        "    item_list = []\n",
        "    user_prediction = predictions[user]\n",
        "\n",
        "    user_prediction = sorted(user_prediction,key=lambda x: (x[1]), reverse=True)\n",
        "    n = 1\n",
        "    for item, rating in user_prediction:\n",
        "        if item  not in item_list:\n",
        "          item_list.append(item)\n",
        "          results_df = pd.concat((results_df, pd.DataFrame(data={user_col:[user],item_col:[item],rating_col:[rating]})))\n",
        "          results.append([user, item, rating])\n",
        "          if n >= topn:\n",
        "              break\n",
        "          n = n + 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Most popular recommendation\n"
      ],
      "metadata": {
        "id": "0c67LS6n1Y-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topn = 10\n",
        "\n",
        "item_popularity_df = data_interaction.groupby(item_col)[rating_col].sum().sort_values(ascending=False).reset_index()\n",
        "\n",
        "predictions = {}\n",
        "\n",
        "for real_user_id in data_interaction_test.userId:\n",
        "    predictions[real_user_id] = []\n",
        "    items_to_ignore = data_interaction_train[data_interaction_train[user_col] == real_user_id]['movieId'].values\n",
        "    item_popularity_df_user = item_popularity_df[~item_popularity_df[item_col].isin(items_to_ignore)]\n",
        "    predictions[real_user_id].append(item_popularity_df_user.head(topn)[item_col].values.tolist())"
      ],
      "metadata": {
        "id": "JyWJBqGz1blh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "results_df = pd.DataFrame(columns = [user_col, item_col, rating_col])\n",
        "\n",
        "for user in predictions:\n",
        "    user_prediction = predictions[user][0]\n",
        "    for item in user_prediction:\n",
        "        rating = 1.\n",
        "        results_df = pd.concat((results_df, pd.DataFrame(data={user_col:[user],item_col:[item],rating_col:[rating]})))\n",
        "        results.append([user, item, rating])"
      ],
      "metadata": {
        "id": "qQ51-oYe1djY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random recommendation"
      ],
      "metadata": {
        "id": "K-A_VQKP1hFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topn = 10\n",
        "\n",
        "predictions = {}\n",
        "\n",
        "for real_user_id in data_interaction_test.user_id:\n",
        "    predictions[real_user_id] = []\n",
        "    items_to_ignore = data_interaction_train[data_interaction_train[user_col] == real_user_id][item_col].values\n",
        "    item_df_user = data_interaction[~data_interaction[item_col].isin(items_to_ignore)]\n",
        "    predictions[real_user_id].append(random.sample(set(item_df_user['track_id'].values), topn))"
      ],
      "metadata": {
        "id": "68Z2iimV1pAk"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "RZiCTldp-GDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "results_df = pd.DataFrame(columns = [user_col, item_col, rating_col])\n",
        "\n",
        "for user in predictions:\n",
        "    user_prediction = predictions[user][0]\n",
        "    for item in user_prediction:\n",
        "        rating = 1.\n",
        "        results_df = pd.concat((results_df, pd.DataFrame(data={user_col:[user],item_col:[item],rating_col:[rating]})))\n",
        "        results.append([user, item, rating])"
      ],
      "metadata": {
        "id": "T6xHh03Y1qFu"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxzLZWaLAhUZ"
      },
      "source": [
        "# Evaluate predictions\n",
        "\n",
        "Scores: F1@10, ndcg, MAP@k"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ndcg_at(predictions, labels, k=10, assume_unique=True):\n",
        "    \"\"\"Compute the normalized discounted cumulative gain at K.\n",
        "    Compute the average NDCG value of all the queries, truncated at ranking\n",
        "    position k. The discounted cumulative gain at position k is computed as:\n",
        "        sum,,i=1,,^k^ (2^{relevance of ''i''th item}^ - 1) / log(i + 1)\n",
        "    and the NDCG is obtained by dividing the DCG value on the ground truth set.\n",
        "    In the current implementation, the relevance value is binary.\n",
        "    If a query has an empty ground truth set, zero will be used as\n",
        "    NDCG together with a warning.\n",
        "    Source: https://gist.github.com/tgsmith61591/d8aa96ac7c74c24b33e4b0cb967ca519\n",
        "    Parameters\n",
        "    ----------\n",
        "    predictions : array-like, shape=(n_predictions,)\n",
        "        The prediction array. The items that were predicted, in descending\n",
        "        order of relevance.\n",
        "    labels : array-like, shape=(n_ratings,)\n",
        "        The labels (positively-rated items).\n",
        "    k : int, optional (default=10)\n",
        "        The rank at which to measure the NDCG.\n",
        "    assume_unique : bool, optional (default=True)\n",
        "        Whether to assume the items in the labels and predictions are each\n",
        "        unique. That is, the same item is not predicted multiple times or\n",
        "        rated multiple times.\n",
        "    Examples\n",
        "    --------\n",
        "    >>> # predictions for 3 users\n",
        "    >>> preds = [[1, 6, 2, 7, 8, 3, 9, 10, 4, 5],\n",
        "    ...          [4, 1, 5, 6, 2, 7, 3, 8, 9, 10],\n",
        "    ...          [1, 2, 3, 4, 5]]\n",
        "    >>> # labels for the 3 users\n",
        "    >>> labels = [[1, 2, 3, 4, 5], [1, 2, 3], []]\n",
        "    >>> ndcg_at(preds, labels, 3)\n",
        "    0.3333333432674408\n",
        "    >>> ndcg_at(preds, labels, 10)\n",
        "    0.48791273434956867\n",
        "    References\n",
        "    ----------\n",
        "    .. [1] K. Jarvelin and J. Kekalainen, \"IR evaluation methods for\n",
        "           retrieving highly relevant documents.\"\n",
        "    \"\"\"\n",
        "\n",
        "    def _inner_ndcg(pred, lab):\n",
        "        # if we do NOT assume uniqueness, the set is a bit different here\n",
        "        if not assume_unique:\n",
        "            lab = np.unique(lab)\n",
        "\n",
        "        n_lab = lab.shape[0]\n",
        "        n_pred = pred.shape[0]\n",
        "        n = min(max(n_pred, n_lab), k)  # min(min(p, l), k)?\n",
        "\n",
        "        # similar to mean_avg_prcsn, we need an arange, but this time +2\n",
        "        # since python is zero-indexed, and the denom typically needs +1.\n",
        "        # Also need the log base2...\n",
        "        arange = np.arange(n, dtype=np.float32)  # length n\n",
        "\n",
        "        # since we are only interested in the arange up to n_pred, truncate\n",
        "        # if necessary\n",
        "        arange = arange[:n_pred]\n",
        "        denom = np.log2(arange + 2.)  # length n\n",
        "        gains = 1. / denom  # length n\n",
        "\n",
        "        # compute the gains where the prediction is present in the labels\n",
        "        dcg_mask = np.in1d(pred[:n], lab, assume_unique=assume_unique)\n",
        "        dcg = gains[dcg_mask].sum()\n",
        "\n",
        "        # the max DCG is sum of gains where the index < the label set size\n",
        "        max_dcg = gains[arange < n_lab].sum()\n",
        "        return dcg / max_dcg\n",
        "\n",
        "\n",
        "    return _inner_ndcg(predictions, labels)"
      ],
      "metadata": {
        "id": "81X0D6wvfHKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "8DTstEsi72xS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "f636195a-b2f3-4676-d67a-4f67417b1583"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-6b1ba770a6d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m     )\n\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f-score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m     )\n\u001b[1;32m   1272\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4993, 4669]"
          ]
        }
      ],
      "source": [
        "scores = []\n",
        "for user, df in results_df.groupby(user_col):\n",
        "  df = df.drop_duplicates(subset=item_col)\n",
        "  y_true_sorted = data_interaction_test.loc[data_interaction_test[user_col] == user].sort_values(rating_col, ascending=False)\n",
        "  y_true_df = pd.merge(data_items_eval[[item_col]], y_true_sorted[[item_col, rating_col]], 'left').fillna(0)\n",
        "  y_true_ndcg = y_true_df[rating_col].values\n",
        "  y_true_df.loc[y_true_df[rating_col] > 0, rating_col] = 1\n",
        "  y_true = y_true_df[rating_col].values\n",
        "\n",
        "  y_pred_df = pd.merge(data_items_eval[[item_col]], df[[item_col, rating_col]], 'left').fillna(0)\n",
        "  y_pred_ndcg = y_pred_df[rating_col].values\n",
        "  y_pred_df.loc[y_pred_df[rating_col] > 0, rating_col] = 1\n",
        "  y_pred = y_pred_df[rating_col].values\n",
        "\n",
        "  if y_true.sum() >= 1:\n",
        "    score = f1_score(y_true, y_pred)\n",
        "    scores.append(score)\n",
        "\n",
        "print(\"F1 Score: \", np.mean(scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaONzUp8rsKH"
      },
      "source": [
        "# Interpretability of Bias\n",
        "\n",
        "- Find correlations between user gender and item gender (Pearsons correlation)\n",
        "- For each track get proportion of female/male user => compare train and recommendataion data\n",
        "- Check if genderness increased/decreased in recommendations (in comparision to training data) \n",
        "- Compare distribution of genderness between history and recommendations \n",
        "  - \"Delta Metric of Genderness\" (https://arxiv.org/pdf/2108.06973.pdf)\n",
        "  - Proportion tests: Fisher exact test, Chi-Square\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLkaN3VRONj6"
      },
      "outputs": [],
      "source": [
        "data_artists = pd.read_csv(\"data_artists.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "data_artists.columns = ['track_artist', 'type', 'gender_artist']\n",
        "data_user_track_interaction = pd.read_csv(\"data_user_track_interaction.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)\n",
        "data_user = pd.read_csv(\"data_user.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)\n",
        "data_user.columns = ['user_id', 'gender_user']\n",
        "\n",
        "a = []\n",
        "for i in  data_artists.track_artist.values:\n",
        "  a.append(i.lower())\n",
        "data_artists['track_artist'] = a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dewGb1xmPBXN"
      },
      "outputs": [],
      "source": [
        "df_tmp = pd.merge(data_user_track_interaction, data_user, 'inner')\n",
        "df_all = pd.merge(df_tmp, data_artists, on = 'track_artist').drop_duplicates()\n",
        "df_all = df_all.loc[(df_all['gender_artist'] != 'Unknown') & (df_all['gender_artist'] != 'other')]\n",
        "\n",
        "replace_dict1 = {'m' : 0, 'f' : 1}\n",
        "replace_dict2 = {'male' : 0, 'female' : 1}\n",
        "df_all['gender_user'] = df_all['gender_user'].replace(replace_dict1)\n",
        "df_all['gender_artist'] = df_all['gender_artist'].replace(replace_dict2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgDbgyUFYVPF"
      },
      "source": [
        "## Correlation between user and item gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4aOub4YUaga",
        "outputId": "1f0213c6-3027-44c5-e687-ff66dcc2ee80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In the history data, all female users listen to 8.3 % female itmes.\n",
            "In the history data, all male users listen to 2.67 % female itmes.\n",
            "The attributes gender_user and gender_artist show a correlation of  0.10665398232086548\n"
          ]
        }
      ],
      "source": [
        "# Proportion of female items in all female user\n",
        "prop_female = 0\n",
        "# Proportion of female items in all male user\n",
        "prop_male = 0\n",
        "for group, df in df_all.groupby('gender_user'):\n",
        "  if group == 0:\n",
        "    prop_male = df.gender_artist.sum() / len(df)\n",
        "  else:\n",
        "    prop_female = df.gender_artist.sum() / len(df)\n",
        "\n",
        "print(f'In the history data, all female users listen to {round(prop_female*100, 2)} % female itmes.')\n",
        "print(f'In the history data, all male users listen to {round(prop_male*100, 2)} % female itmes.')\n",
        "\n",
        "# Pearson correlation\n",
        "print('The attributes gender_user and gender_artist show a correlation of ', df_all.gender_user.corr(df_all.gender_artist))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_7r-GujbVZV",
        "outputId": "ca6a1922-b142-4ad9-ad24-e03caec1b036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1905224050321245e-05\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import fisher_exact\n",
        "tab = pd.crosstab(df_all.gender_user, df_all.gender_artist)\n",
        "stats, p_value = fisher_exact(tab)\n",
        "print(p_value)\n",
        "# if p-value <= 0.05 => gender_user and gender_artist are independent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEiaFN1bYdFE"
      },
      "source": [
        "## Delta metric of genderness\n",
        "\n",
        " For user u_i: (prop_female(rec) - prop_female(history)) / prop_female(history)\n",
        "\n",
        " If positive: more female tracks are recommended to the user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYomuJrr3Qj_"
      },
      "outputs": [],
      "source": [
        "df_tmp = pd.merge(results_df, data_user, 'inner')\n",
        "df_artists_tmp = pd.merge(df_tmp, data_user_track_interaction[['track_artist', 'track_id']])\n",
        "df_rec = pd.merge(df_artists_tmp, data_artists, on = 'track_artist').drop_duplicates()\n",
        "df_rec = df_rec.loc[(df_rec['gender_artist'] != 'Unknown') & (df_rec['gender_artist'] != 'other')]\n",
        "df_rec['gender_user'] = df_rec['gender_user'].replace(replace_dict1)\n",
        "df_rec['gender_artist'] = df_rec['gender_artist'].replace(replace_dict2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP_j3yQgd6Gx",
        "outputId": "75eedc37-c1a0-42de-adc8-50b810d53992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The value of delta is -1.0 and therefore more male tracks are recommended to user.\n"
          ]
        }
      ],
      "source": [
        "prop_female_rec = df_rec.gender_artist.sum()\n",
        "prop_female_history = df_all.gender_artist.sum()\n",
        "delta = (prop_female_rec - prop_female_history) / prop_female_history\n",
        "\n",
        "if delta > 0:\n",
        "  print(f'The value of delta is {delta} and therefore more female tracks are recommended to user.')\n",
        "else:\n",
        "  print(f'The value of delta is {delta} and therefore more male tracks are recommended to user.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W5yg61kZJOV"
      },
      "source": [
        "## Proportion test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IV5pBGTjYfsO"
      },
      "outputs": [],
      "source": [
        "# Fisher exact test\n",
        "\n",
        "from scipy.stats import fisher_exact\n",
        "tab = pd.crosstab(df_rec.gender_artist, df_all.gender_artist)\n",
        "stats, p_value = fisher_exact(tab)\n",
        "if p_value <= 0.05:\n",
        "  print(f'The attributes gender_artist of the history and recommendation data are significantly independent.')\n",
        "\n",
        "# if p-value <= 0.05 => gender_x and gender_y are independent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-aNSsd8cv6h",
        "outputId": "ed283829-2b4d-4865-f136-f4f439900c17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/stats/proportion.py:824: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  prop = count * 1. / nobs\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/stats/proportion.py:840: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  nobs_fact = np.sum(1. / nobs)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/stats/weightstats.py:671: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  zstat = value / std_diff\n"
          ]
        }
      ],
      "source": [
        "# z-test\n",
        "\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "significance = 0.005\n",
        "sample_size_hist = df_all.gender_artist.count()\n",
        "sample_success_hist = df_all.gender_artist.sum()\n",
        "sample_success_rec = df_rec.gender_artist.count()\n",
        "sample_size_rec = df_rec.gender_artist.sum()\n",
        "successes = np.array([sample_success_hist, sample_success_rec])\n",
        "samples = np.array([sample_size_hist, sample_size_rec])\n",
        "stat, p_value = proportions_ztest(count=successes, nobs=samples,  alternative='two-sided')\n",
        "if p_value <= 0.05:\n",
        "  print(f'The proportions of gender_artist of the history and recommendation data are significantly different.')\n",
        "# if p-value <= 0.05 => the proportions are significantly different"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict artist gender"
      ],
      "metadata": {
        "id": "NtIQzQEH2vhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "o_NzF7QQ3J6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_all_info = pd.read_csv(\"music/data_all_info.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "data_all_info = data_all_info.loc[data_all_info.artist_gender != 'other' ]"
      ],
      "metadata": {
        "id": "FducXCFxKURy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = feature_vectors"
      ],
      "metadata": {
        "id": "8XV1iDFGB0mF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features = pd.DataFrame()\n",
        "id_col = []\n",
        "\n",
        "for id in data_interaction_test[item_col].unique():\n",
        "  id_col.append(id)\n",
        "  df_features = df_features.append(pd.DataFrame(input[id][0].detach().numpy()))\n",
        "\n",
        "df_features[item_col] = id_col"
      ],
      "metadata": {
        "id": "Zv1QvFM3I22n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features = pd.merge(df_features, data_all_info)"
      ],
      "metadata": {
        "id": "EBOE0G_TJ28n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features.loc[df_features.artist_gender == 'female', 'artist_gender'] = 0\n",
        "df_features.loc[df_features.artist_gender == 'male', 'artist_gender'] = 1\n",
        "df_features.artist_gender = df_features.artist_gender.astype('int')"
      ],
      "metadata": {
        "id": "YOQ6VKT_IVyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_features.iloc[:,:128]\n",
        "y = df_features.artist_gender\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.4, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "2ic2xa382unN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred=clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test.values, y_pred))\n",
        "print(\"Balanced Accuracy:\", metrics.balanced_accuracy_score(y_test.values, y_pred))\n",
        "print(\"Recall: \", metrics.recall_score(y_test.values, y_pred))\n",
        "print(\"Precision: \", metrics.precision_score(y_test.values, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h50TBcLs3G7l",
        "outputId": "6a0f5c73-0cde-43ab-f254-0c7429c0e2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7887323943661971\n",
            "Balanced Accuracy: 0.7465686274509804\n",
            "Recall:  0.8431372549019608\n",
            "Precision:  0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "feature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\n",
        "feature_imp.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQSgoDfe4Cc4",
        "outputId": "d28f5393-a801-4ce2-bd4a-a85e55df7656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104    0.226804\n",
              "98     0.140306\n",
              "17     0.131687\n",
              "81     0.114796\n",
              "127    0.111745\n",
              "62     0.091315\n",
              "5      0.083488\n",
              "111    0.051955\n",
              "3      0.047903\n",
              "69     0.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d-l5O-0D2dm"
      },
      "source": [
        "---------------------------\n",
        "\n",
        "# Next steps\n",
        "\n",
        "[x] Train test split \n",
        "\n",
        "[x] Implement CV\n",
        "\n",
        "[x] Balance data set (use as many listened as unlistened tracks - randomly chosing them)\n",
        "\n",
        "[x] Use Popularity model as baseline\n",
        "\n",
        "[x] Check index behaviour!!! (pos2item,...)\n",
        "\n",
        "[x] Test/train split (https://colab.research.google.com/github/d2l-ai/d2l-en-colab/blob/master/chapter_recommender-systems/movielens.ipynb)\n",
        "\n",
        "[x] Verify BERT Tokenizer\n",
        "\n",
        "[x] Verify data reading with new movie data\n",
        "\n",
        "[x] Try out gender interpretability\n",
        "\n",
        "[x] Add tags data (instead of lyrics)\n",
        "\n",
        "[x] Get more data\n",
        "\n",
        "[x] Clean lyrics data (remove non-english ones and repeated parts)\n",
        "\n",
        "[x] Use embedding of model to predict gender of artist\n",
        "\n",
        "[x] Try to find song writer gender (not priority) => tried this out but could not find a general solution\n",
        "\n",
        "[ ] Implement ndcg (https://github.com/Jenniferz28/Collaborative-Filtering-Recommendation/blob/69a2400736a628de34620318abe861cc9a19e621/ndcg.py#L77)\n",
        "\n",
        "[x] Clean up code and move to repository\n",
        "\n",
        "[x] Implement evaluation with using all items in dataset\n",
        "\n",
        "[ ] BERT make sure this is correct!\n",
        "\n",
        "[ ] Try out correlation interpretability things (e.g. \"Exploring Artist Gender Bias in Music Recommendation\"\n",
        "\n",
        "[ ] Remove 'important' feature vector from recommendataion model and compare recommendation performance + prediction perforamcne\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "UaONzUp8rsKH",
        "hgDbgyUFYVPF",
        "UEiaFN1bYdFE",
        "_W5yg61kZJOV"
      ],
      "machine_shape": "hm",
      "name": "MasterThesis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPE7FTzL8YxVGn0VLY6yNTW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "70491ef249434a5a8de8a33ec18725f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb160db681944f44b33492023d8c76d5",
              "IPY_MODEL_d7111bcf87454b1099a2a3162aafefbb",
              "IPY_MODEL_99018ec3488f4f7b82b87d10c77b8ed0"
            ],
            "layout": "IPY_MODEL_b0a06778441a48d9aa832974be8ab463"
          }
        },
        "bb160db681944f44b33492023d8c76d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c790afb2b79f48f2806a5b26275e5b58",
            "placeholder": "​",
            "style": "IPY_MODEL_0d2cd84af0494b23a782a7f30a81c2b7",
            "value": "Downloading: 100%"
          }
        },
        "d7111bcf87454b1099a2a3162aafefbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_775d440e94f4425196c104fe0d719177",
            "max": 17756393,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4794baae2e146a38e050f62aa7de759",
            "value": 17756393
          }
        },
        "99018ec3488f4f7b82b87d10c77b8ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7de23e2a2584c0d9804b9eba9eb842e",
            "placeholder": "​",
            "style": "IPY_MODEL_f5af5c67acef4d2e99ef38e99e999911",
            "value": " 16.9M/16.9M [00:00&lt;00:00, 42.9MB/s]"
          }
        },
        "b0a06778441a48d9aa832974be8ab463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c790afb2b79f48f2806a5b26275e5b58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d2cd84af0494b23a782a7f30a81c2b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "775d440e94f4425196c104fe0d719177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4794baae2e146a38e050f62aa7de759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7de23e2a2584c0d9804b9eba9eb842e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5af5c67acef4d2e99ef38e99e999911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}