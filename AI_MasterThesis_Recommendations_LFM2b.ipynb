{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Katrin-Leberfinger/Hybrid-gender-debiased-music-recommendation/blob/main/AI_MasterThesis_Recommendations_LFM2b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWHMmzSHaV4j",
        "outputId": "83aa96fa-0d9d-475a-cbcd-7fdb10ca9b01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 7.1 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 49.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 41.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L9D-5zOmltBw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from transformers import BertConfig, BertPreTrainedModel, BertModel, BertForSequenceClassification\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertModel, AdamW\n",
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import gc                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXEH2KDKXjCM"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets"
      ],
      "metadata": {
        "id": "xrv1WB2C6l-f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XlA7ckWp1_mg"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class LFM2bDataset(Dataset):\n",
        "    def __init__(self, data_all,tokenizer,max_length, text_col, item2pos, user2id):\n",
        "        super(LFM2bDataset, self).__init__()\n",
        "        self.data_all = data_all\n",
        "        self.max_length = max_length\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text_col = text_col\n",
        "        self.item2pos = item2pos\n",
        "        self.user2id = user2id\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data_all)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        text1 = self.data_all.iloc[index][self.text_col]\n",
        "        user_id = self.user2id[ self.data_all.iloc[index]['user_id']]\n",
        "        track_id = self.item2pos[ self.data_all.iloc[index]['track_id']]\n",
        "        \n",
        "        # inputs = tokenizer.encode_plus(\n",
        "        #     text1, \n",
        "        #     None,\n",
        "        #     add_special_tokens=True,\n",
        "        #     max_length = self.max_length,\n",
        "        #     pad_to_max_length=True   \n",
        "        #)\n",
        "\n",
        "        inputs = tokenizer.encode_plus(\n",
        "                text1, \n",
        "                add_special_tokens=True,\n",
        "                padding='max_length',\n",
        "                max_length = self.max_length,\n",
        "                return_tensors='pt',\n",
        "                truncation=True,\n",
        "                return_attention_mask=True\n",
        "                )\n",
        "        ids = inputs[\"input_ids\"]\n",
        "        mask = inputs[\"attention_mask\"]\n",
        "\n",
        "        return {\n",
        "            'input_ids_lyrics': ids.flatten(),\n",
        "            'attention_mask_lyrics': mask.flatten(),\n",
        "            'user_id': torch.tensor(user_id, dtype=torch.long),\n",
        "             'track_id': torch.tensor(track_id, dtype=torch.long),\n",
        "            'target': torch.tensor(self.data_all.iloc[index]['count'], dtype=torch.float)\n",
        "            }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r5XACwlUqC9Z"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class LFM2bDatasetMulitpleText(Dataset):\n",
        "    def __init__(self, data_all,tokenizer,max_length, item2pos, user2id):\n",
        "        super(LFM2bDatasetMulitpleText, self).__init__()\n",
        "        self.data_all = data_all\n",
        "        self.max_length = max_length\n",
        "        self.tokenizer = tokenizer\n",
        "        self.item2pos = item2pos\n",
        "        self.user2id = user2id\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data_all)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        text1 = self.data_all.iloc[index]['lyrics_cleaned']\n",
        "        text2 = self.data_all.iloc[index]['tags']\n",
        "        text3 = self.data_all.iloc[index]['abstract']\n",
        "        user_id = self.user2id[ self.data_all.iloc[index]['user_id']]\n",
        "        track_id = self.item2pos[ self.data_all.iloc[index]['track_id']]\n",
        "        \n",
        "        inputs1 = tokenizer.encode_plus(\n",
        "            text1, \n",
        "            add_special_tokens=True,\n",
        "            padding='max_length',\n",
        "            max_length = self.max_length,\n",
        "            return_tensors='pt',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True\n",
        "            \n",
        "        )\n",
        "        ids1 = inputs1[\"input_ids\"]\n",
        "        mask1 = inputs1[\"attention_mask\"]\n",
        "\n",
        "        inputs2 = tokenizer.encode_plus(\n",
        "            text2, \n",
        "            add_special_tokens=True,\n",
        "            padding='max_length',\n",
        "            max_length = self.max_length,\n",
        "            return_tensors='pt',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True\n",
        "            \n",
        "        )\n",
        "        ids2 = inputs2[\"input_ids\"]\n",
        "        mask2 = inputs2[\"attention_mask\"]\n",
        "\n",
        "        inputs3 = tokenizer.encode_plus(\n",
        "            text3, \n",
        "            add_special_tokens=True,\n",
        "            padding='max_length',\n",
        "            max_length = self.max_length,\n",
        "            return_tensors='pt',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True\n",
        "            \n",
        "        )\n",
        "        ids3 = inputs1[\"input_ids\"]\n",
        "        mask3 = inputs1[\"attention_mask\"]\n",
        "\n",
        "        return {\n",
        "            'input_ids_lyrics': torch.tensor(ids1, dtype=torch.long),\n",
        "            'attention_mask_lyrics': torch.tensor(mask1, dtype=torch.long),\n",
        "            'input_ids_tags': torch.tensor(ids2, dtype=torch.long),\n",
        "            'attention_mask_tags': torch.tensor(mask2, dtype=torch.long),\n",
        "            'input_ids_abstract': torch.tensor(ids3, dtype=torch.long),\n",
        "            'attention_mask_abstract': torch.tensor(mask3, dtype=torch.long),\n",
        "            'user_id': torch.tensor(user_id, dtype=torch.long),\n",
        "            'track_id': torch.tensor(track_id, dtype=torch.long),\n",
        "            'target': torch.tensor(self.data_all.iloc[index]['count'], dtype=torch.float)\n",
        "            }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzTFm7XWXmXv",
        "outputId": "c8ec3069-a970-4e03-f4e1-f4cad5875852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWWKtwJxXmQC",
        "outputId": "c8a76016-2951-4f9b-ebd2-dfb2d4a4892a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Master Thesis/data\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Master\\ Thesis/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf103qDF0cNv"
      },
      "source": [
        "## Read Data: Lyrics "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lTSGXhgqhfXI"
      },
      "outputs": [],
      "source": [
        "data_tracks_lyrics = pd.read_csv(\"music/data_tracks_lyrics.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "data_tracks_tags_lyrics = pd.read_csv(\"music/data_tracks_tags_lyrics.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1).dropna().drop_duplicates('track_id')\n",
        "data_bio = pd.read_csv(\"music/data_artists_biography.txt\", sep=\",\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "data_interaction = pd.read_csv(\"music/data_user_track_interaction_old.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)\n",
        "\n",
        "data_tracks_tags_lyrics = data_tracks_tags_lyrics.merge(data_bio)\n",
        "data_interaction = data_interaction.merge(data_tracks_tags_lyrics[['track_id']].drop_duplicates(), on = 'track_id', how = 'inner').drop_duplicates()\n",
        "data_tracks_tags_lyrics = data_tracks_tags_lyrics.merge(data_interaction[['track_id']], on = 'track_id', how = 'inner').drop_duplicates()\n",
        "\n",
        "data_user = pd.read_csv(\"music/data_user.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_movies = pd.read_csv(\"movies/movies_abstracts.csv\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "# data_interaction = pd.read_csv(\"movies/ratings.csv\").drop(['timestamp'],axis=1)\n",
        "\n",
        "# data_movies = pd.merge(data_movies, data_interaction[['movieId']], 'inner').drop_duplicates()\n",
        "# data_interaction = pd.merge(data_interaction, data_movies[['movieId']], 'inner')\n",
        "\n",
        "# data_movies.columns = ['track_id', 'lyrics_cleaned', 'tags', 'abstract']\n",
        "# data_tracks_tags_lyrics = data_movies\n",
        "\n",
        "# data_interaction.columns = ['user_id', 'track_id', 'count']"
      ],
      "metadata": {
        "id": "vjrZjQCIzTKn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TtZh4wlvnLGy"
      },
      "outputs": [],
      "source": [
        "# import seaborn as sns\n",
        "# sns.set_style('whitegrid')\n",
        "# sns.kdeplot(data_interaction['count'], bw=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZLT9a8oHXhwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b752beb-8f0b-4cb8-b9e2-781757bf6382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:723: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
          ]
        }
      ],
      "source": [
        "# filter out playcount 1\n",
        "data_interaction = data_interaction[data_interaction['count'] != 1]\n",
        "\n",
        "data_interaction.loc[data_interaction['count']<2., 'count'] = 0.\n",
        "data_interaction.loc[data_interaction['count']>=2., 'count'] = 1."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_interaction.loc[data_interaction['count']<4., 'count'] = 0.\n",
        "# data_interaction.loc[data_interaction['count']>=4., 'count'] = 1."
      ],
      "metadata": {
        "id": "M6Kgjib426p4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylBY96MuqFyc"
      },
      "source": [
        "## CV and balance data set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove user with too little playcount\n",
        "# add negative samples\n",
        "selected_items = []\n",
        "for track_id,df in data_interaction.groupby('track_id'):\n",
        "  if len(df) >= 5:\n",
        "    selected_items.append(track_id)\n",
        "data_interaction = data_interaction.loc[(data_interaction.track_id.isin(selected_items))]\n",
        "\n",
        "import random\n",
        "random.seed(123)\n",
        "data_interaction_new = pd.DataFrame(columns = data_interaction.columns)\n",
        "for user_id,df in data_interaction.groupby('user_id'):\n",
        "  if len(df) >= 15:\n",
        "    n_diff = len(df[df['count'] == 1]) - len(df[df['count'] == 0])\n",
        "    if n_diff > 2:\n",
        "      df_tmp = df.merge(data_interaction[['track_id']], how = 'right')\n",
        "      neg_list = random.sample(list(df_tmp[np.isnan(df_tmp.user_id)].track_id.values), n_diff)\n",
        "      df_neg = pd.DataFrame({'user_id': user_id, 'track_id':neg_list, 'count':0})\n",
        "      data_interaction_new=data_interaction_new.append(df)\n",
        "      data_interaction_new=data_interaction_new.append(df_neg)\n",
        "    else:\n",
        "      data_interaction_new = data_interaction_new.append(df)\n",
        "\n",
        "data_interaction_new = shuffle(data_interaction_new)"
      ],
      "metadata": {
        "id": "xQxTlqXGZqYo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_interaction_new = data_interaction\n",
        "# data_interaction_new = shuffle(data_interaction_new)"
      ],
      "metadata": {
        "id": "ORDXqILwhCc4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vgNXpip-7pN6"
      },
      "outputs": [],
      "source": [
        "data_interaction_new = data_interaction_new.merge(data_tracks_tags_lyrics[['track_id', 'lyrics_cleaned', 'tags', 'abstract']]).drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "n2XOZyN3LZte"
      },
      "outputs": [],
      "source": [
        "data_tracks_tags_lyrics = data_tracks_tags_lyrics.merge(data_interaction_new[['track_id']]).drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rating_col = 'count'\n",
        "item_col = 'track_id'\n",
        "user_col = 'user_id'\n",
        "data_items_eval = data_tracks_tags_lyrics"
      ],
      "metadata": {
        "id": "rsThv-mXkAEv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MR65uPJ6qE9R"
      },
      "outputs": [],
      "source": [
        "np.random.seed(123)\n",
        "data_interaction_new['fold'] = np.random.randint(1, 6, data_interaction_new.shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(123)\n",
        "for _,df in data_interaction_new.groupby('fold'):\n",
        "  len_pos = len(df[df[rating_col]==1])\n",
        "  len_neg = len(df[df[rating_col]==0])\n",
        "  if len_pos < len_neg:\n",
        "    df = df[df[rating_col]==0].sample(len_pos).append(df[df[rating_col]==1])\n",
        "  elif len_pos > len_neg:\n",
        "    df = df[df[rating_col]==1].sample(len_pos).append(df[df[rating_col]==0])"
      ],
      "metadata": {
        "id": "_6b2a71hTemj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_fold = 1\n",
        "val_fold = 2\n",
        "\n",
        "\n",
        "data_interaction_train = data_interaction_new.loc[((data_interaction_new.fold != test_fold) & (data_interaction_new.fold != val_fold)), ['user_id', 'track_id', 'count', 'lyrics_cleaned', 'tags', 'abstract']]\n",
        "data_interaction_test = data_interaction_new.loc[data_interaction_new.fold == test_fold, ['user_id', 'track_id', 'count', 'lyrics_cleaned', 'tags', 'abstract']]\n",
        "data_interaction_val = data_interaction_new.loc[data_interaction_new.fold == val_fold,  ['user_id', 'track_id', 'count', 'lyrics_cleaned', 'tags', 'abstract']]"
      ],
      "metadata": {
        "id": "StCFnT0dTifD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_interaction_test)"
      ],
      "metadata": {
        "id": "z5kbbLcf-3p0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40309e9d-41fa-4ec0-8b45-ef0d24b359a9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31083"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kVsfyhSr7IcO"
      },
      "outputs": [],
      "source": [
        "# itermin solution (maybe change later)\n",
        "selected_user = []\n",
        "for user_id,df in data_interaction_test.groupby('user_id'):\n",
        "  df_tmp = df.merge(data_tracks_tags_lyrics[['track_id']].drop_duplicates(), how = 'right').drop_duplicates()\n",
        "  items_to_ignore = data_interaction_train[data_interaction_train[user_col] == user_id][item_col].values\n",
        "  df_tmp = df_tmp[~df_tmp['track_id'].isin(items_to_ignore)]\n",
        "  neg_list = list(set(df_tmp.loc[df_tmp.isna().any(axis=1),].track_id.values))\n",
        "  df_neg = pd.DataFrame({'user_id': user_id, 'track_id':neg_list, 'count':0})\n",
        "  if df['count'].sum() >= 10:\n",
        "    data_interaction_test=data_interaction_test.append(df_neg)\n",
        "    selected_user.append(user_id)\n",
        "  \n",
        "data_interaction_test = data_interaction_test[['user_id', 'track_id', 'count']].merge(data_tracks_tags_lyrics[['track_id', 'lyrics_cleaned', 'tags', 'abstract']], on = 'track_id', how = 'left').drop_duplicates()\n",
        "data_interaction_test = data_interaction_test.loc[(data_interaction_test.user_id.isin(selected_user))]\n",
        "data_interaction_test = shuffle(data_interaction_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_interaction_test)"
      ],
      "metadata": {
        "id": "SYUiRd9j8ucB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b87acb68-1add-43d7-fbdc-3d2f3321992b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "930098"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YzaZogbavPo7"
      },
      "outputs": [],
      "source": [
        "data_interaction_test[['track_id']] = data_interaction_test[['track_id']].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "MMZko0cZAAL9"
      },
      "outputs": [],
      "source": [
        "pos2item = {i:v for i, v in enumerate(data_tracks_tags_lyrics.track_id.sort_values().unique())}\n",
        "item2pos = {v:i for i, v in enumerate(data_tracks_tags_lyrics.track_id.sort_values().unique())}\n",
        "\n",
        "id2user = {i:v for i, v in enumerate(data_interaction.user_id.sort_values().unique())}\n",
        "user2id = {v:i for i, v in enumerate(data_interaction.user_id.sort_values().unique())}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1VnHcVWBFIP"
      },
      "source": [
        "# Ask Me Anything Rating\n",
        "\n",
        "Code source: https://github.com/nlp-deepcbrs/amar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ndcg(df, rel_pred, k):\n",
        "\n",
        "  rel_true = np.zeros(len(df))\n",
        "  rel_true[:k] = 1\n",
        "\n",
        "  def _dcg(rel):\n",
        "    i = np.arange(1, len(rel)+ 1)\n",
        "    denom = np.log2(i + 1)\n",
        "    dcg = np.sum(rel / denom)\n",
        "    return dcg\n",
        "\n",
        "  return _dcg(rel_pred) / _dcg(rel_true)\n",
        "\n"
      ],
      "metadata": {
        "id": "RNyclnHsnMMm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbf_Xg4sE_gu"
      },
      "source": [
        "## **BERT Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "p_Vn354IdSzX"
      },
      "outputs": [],
      "source": [
        "class AMARBase(nn.Module):\n",
        "  \"\"\"Model with LT tables for user and items.\"\"\"\n",
        "  def __init__(self, hidden_dense_layer_size, item_embeddings_size, user_embeddings_size, num_users, num_items):\n",
        "      super(AMARBase, self).__init__()\n",
        "\n",
        "      self.hidden_dense_layer_size = hidden_dense_layer_size\n",
        "      self.item_embeddings_size = item_embeddings_size\n",
        "      self.user_embeddings_size = user_embeddings_size\n",
        "      self.num_items = num_items\n",
        "      self.num_users = num_users\n",
        "\n",
        "      self.model1_layer1 = nn.Embedding(self.num_items, self.item_embeddings_size, max_norm = 1.)\n",
        "      nn.init.uniform_(self.model1_layer1.weight, a=-0.05, b=0.05)\n",
        "\n",
        "      self.model2_layer1 = nn.Embedding(self.num_users, self.user_embeddings_size, max_norm = 1.)\n",
        "      nn.init.uniform_(self.model2_layer1.weight, a=-0.05, b=0.05)\n",
        "\n",
        "      self.linear1 = nn.Linear(self.hidden_dense_layer_size, 128)\n",
        "\n",
        "      self.relu = nn.ReLU()\n",
        "      \n",
        "      self.linear2 = nn.Linear(128, 1)\n",
        "\n",
        "      self.drop =  nn.Dropout(p=0.2)\n",
        "      self.sigmoid = nn.Sigmoid()\n",
        "      \n",
        "  def forward(self, x):\n",
        "      y1 = self.model1_layer1(x[0])\n",
        "      \n",
        "      y2 = self.model2_layer1(x[2])\n",
        "\n",
        "      y = torch.cat((y1, y2), 1) \n",
        "      # Matrix factorization: https://blog.fastforwardlabs.com/2018/04/10/pytorch-for-recommenders-101.html\n",
        "    #  y = (y1*y2).sum(1)\n",
        "      y = self.linear1(y)\n",
        "      y = self.relu(y)\n",
        "      y = self.linear2(y)\n",
        "      return self.sigmoid(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
        "MODEL_NAME = 'distilbert-base-uncased'\n",
        "config = AutoConfig.from_pretrained(MODEL_NAME, num_labels = 2)\n",
        "\n",
        "hidden_dense_layer_size=778\n",
        "\n",
        "MODEL_NAME = 'prajjwal1/bert-tiny'\n",
        "#MODEL_NAME = 'bert-base-uncased'"
      ],
      "metadata": {
        "id": "Im1yGgNA0RZX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0330da87c948473b800a1407dda1d1ce",
            "719d5b433992413f8270ed622964257a",
            "37a16a63da684237b393bb8f5543a1d1",
            "8a72ac040aed421f872d315f3ddacb29",
            "09b65840e48743199ad5135c382b2006",
            "136426d3f3ed4c05aa70a27adb2b1528",
            "05ce98d6528c48b2893a026bd425b475",
            "0bbc49de1ccb4c8fa5f18633f1da0e1e",
            "62b367446c3147178159f7aa7ba84de9",
            "eaa8b296137147d8a5ff53178de02319",
            "ccae6e1b35f9412ab7ff868559d13f40"
          ]
        },
        "outputId": "b0633a3f-5aa4-4c9d-e84a-e0cd69ce61e2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0330da87c948473b800a1407dda1d1ce"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GHWjCxuHb6cX"
      },
      "outputs": [],
      "source": [
        "# class AMARBert(nn.Module):\n",
        "#     def __init__(self, hidden_dense_layer_size, item_embeddings_size, user_embeddings_size, item_text_embeddings_size, num_users, num_items, hidden_layer=32):\n",
        "#         super(AMARBert, self).__init__()\n",
        "\n",
        "#         self.hidden_dense_layer_size = hidden_dense_layer_size\n",
        "#         self.item_embeddings_size = item_embeddings_size\n",
        "#         self.user_embeddings_size = user_embeddings_size\n",
        "#         self.item_text_embeddings_size = item_text_embeddings_size\n",
        "#         self.num_items = num_items\n",
        "#         self.num_users = num_users\n",
        "        \n",
        "#         self.model1_layer2 = BertModel.from_pretrained(MODEL_NAME)\n",
        "#         self.model1_layer3 = nn.Dropout(p=0.3)\n",
        "\n",
        "#         self.model2_layer1 = nn.Embedding(self.num_users, self.user_embeddings_size)\n",
        "#         nn.init.uniform_(self.model2_layer1.weight, a=0.0, b=0.05)\n",
        "\n",
        "#         self.model3_layer1 = nn.Embedding(self.num_items, self.item_embeddings_size)\n",
        "#         nn.init.uniform_(self.model3_layer1.weight, a=0.0, b=0.05)\n",
        "        \n",
        "#         self.linear1 = nn.Linear(self.hidden_dense_layer_size, self.hidden_dense_layer_size)\n",
        "#         nn.init.xavier_uniform(self.linear1.weight)\n",
        "#         self.linear1.bias.data.fill_(0.01)\n",
        "\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.linear2 = nn.Linear(hidden_dense_layer_size, hidden_layer)\n",
        "#         nn.init.xavier_uniform(self.linear2.weight)\n",
        "#         self.linear2.bias.data.fill_(0.01)\n",
        "\n",
        "#         self.linear3 = nn.Linear(hidden_layer, 1)\n",
        "#         nn.init.xavier_uniform(self.linear3.weight)\n",
        "#         self.linear3.bias.data.fill_(0.01)\n",
        "\n",
        "#         self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "#     def forward(self, x):\n",
        "#         output = self.model1_layer2(x[1], attention_mask = x[3])\n",
        "#         y1 = output[0]\n",
        "#         #y1 = y1.mean(axis=2) # alterantive to CLS token, combine with y1[:,0,:] possible\n",
        "#         y1 = y1[:,0,:]\n",
        "#         # \"Since BERT is transformer based contextual model, the idea is [CLS] token would have captured the entire context and would be sufficient for simple downstream tasks such as classification.\"\n",
        "#         y1 = self.model1_layer3(y1)\n",
        "        \n",
        "#         y2 = self.model2_layer1(x[2])\n",
        "\n",
        "#         y3 = self.model3_layer1(x[0])\n",
        "\n",
        "#         y = torch.cat([y1, y2, y3], 1)\n",
        "#         y = self.linear1(y)\n",
        "#         y = self.relu(y)\n",
        "#         y = self.linear2(y)\n",
        "#         y = self.linear3(y)\n",
        "#         return self.sigmoid(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AMARBertMultiple(nn.Module):\n",
        "    def __init__(self, hidden_dense_layer_size, item_embeddings_size, user_embeddings_size, item_text_embeddings_size, num_users, num_items, hidden_layer=32):\n",
        "        super(AMARBertMultiple, self).__init__()\n",
        "\n",
        "        self.hidden_dense_layer_size = hidden_dense_layer_size\n",
        "        self.item_embeddings_size = item_embeddings_size\n",
        "        self.user_embeddings_size = user_embeddings_size\n",
        "        self.item_text_embeddings_size = item_text_embeddings_size\n",
        "        self.num_items = num_items\n",
        "        self.num_users = num_users\n",
        "        \n",
        "        self.model1_layer2 = BertModel.from_pretrained('prajjwal1/bert-tiny')\n",
        "        self.model1_layer3 = nn.Dropout(p=0.2)\n",
        "\n",
        "        self.model4_layer2 = BertModel.from_pretrained('prajjwal1/bert-tiny')\n",
        "        self.model4_layer3 = nn.Dropout(p=0.2)\n",
        "\n",
        "        self.model2_layer1 = nn.Embedding(self.num_users, self.user_embeddings_size, max_norm = 1.)\n",
        "        nn.init.uniform_(self.model2_layer1.weight, a=0.0, b=0.05)\n",
        "\n",
        "        self.model3_layer1 = nn.Embedding(self.num_items, self.item_embeddings_size, max_norm = 1.)\n",
        "        nn.init.uniform_(self.model3_layer1.weight, a=0.0, b=0.05)\n",
        "        \n",
        "        self.linear1 = nn.Linear(self.hidden_dense_layer_size, self.hidden_dense_layer_size)\n",
        "        nn.init.xavier_uniform(self.linear1.weight)\n",
        "        self.linear1.bias.data.fill_(0.01)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_dense_layer_size, hidden_layer)\n",
        "        nn.init.xavier_uniform(self.linear2.weight)\n",
        "        self.linear2.bias.data.fill_(0.01)\n",
        "\n",
        "        self.linear3 = nn.Linear(hidden_layer, 1)\n",
        "        nn.init.xavier_uniform(self.linear3.weight)\n",
        "        self.linear3.bias.data.fill_(0.01)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        output = self.model1_layer2(x[1], attention_mask = x[3])\n",
        "        y1 = output[0]\n",
        "        #y1 = y1.mean(axis=2) # alterantive to CLS token, combine with y1[:,0,:] possible\n",
        "        y1 = y1[:,0,:]\n",
        "        # \"Since BERT is transformer based contextual model, the idea is [CLS] token would have captured the entire context and would be sufficient for simple downstream tasks such as classification.\"\n",
        "        y1 = self.model1_layer3(y1)\n",
        "\n",
        "        output = self.model1_layer2(x[4], attention_mask = x[5])\n",
        "        y4 = output[0]\n",
        "        #y1 = y1.mean(axis=2) # alterantive to CLS token, combine with y1[:,0,:] possible\n",
        "        y4 = y4[:,0,:]\n",
        "        # \"Since BERT is transformer based contextual model, the idea is [CLS] token would have captured the entire context and would be sufficient for simple downstream tasks such as classification.\"\n",
        "        y4 = self.model4_layer3(y4)\n",
        "        \n",
        "        y2 = self.model2_layer1(x[2])\n",
        "\n",
        "        y3 = self.model3_layer1(x[0])\n",
        "\n",
        "        y = torch.cat([y1, y2, y3, y4], 1)\n",
        "        \n",
        "        y = self.linear1(y)\n",
        "        y = self.relu(y)\n",
        "        y = self.linear2(y)\n",
        "        y = self.linear3(y)\n",
        "        \n",
        "        return self.sigmoid(y)\n"
      ],
      "metadata": {
        "id": "63hOMXmqD85X"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AMARBert(nn.Module):\n",
        "    def __init__(self, hidden_dense_layer_size, item_embeddings_size, num_users, hidden_layer=32):\n",
        "        super(AMARBert, self).__init__()\n",
        "        self.model1_layer2 = BertModel.from_pretrained(MODEL_NAME)\n",
        "        self.model1_layer3 = nn.Dropout(p=0.3)\n",
        "\n",
        "        self.model2_layer1 = nn.Embedding(num_users, user_embeddings_size)\n",
        "        \n",
        "        self.linear = nn.Linear(hidden_dense_layer_size, hidden_dense_layer_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_dense_layer_size, hidden_layer)\n",
        "        self.linear3 = nn.Linear(hidden_layer, 1)\n",
        "        \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        output = self.model1_layer2(x[1], attention_mask = x[3])\n",
        "        y1 = output[0]\n",
        "        #y1 = y1.mean(axis=2) # alterantive to CLS token, combine with y1[:,0,:] possible\n",
        "        y1 = y1[:, 0, :]\n",
        "        # pooled_output (=y1) is the output of the CLS token\n",
        "        # \"Since BERT is transformer based contextual model, the idea is [CLS] token would have captured the entire context and would be sufficient for simple downstream tasks such as classification.\"\n",
        "        # https://stackoverflow.com/questions/63673511/how-to-use-the-outputs-of-bert-model?rq=1\n",
        "        # https://towardsdatascience.com/bert-to-the-rescue-17671379687f\n",
        "        y1 = self.model1_layer3(y1)\n",
        "        \n",
        "        y2 = self.model2_layer1(x[2])\n",
        "\n",
        "        y = torch.cat([y1, y2], 1)\n",
        "        y = self.linear(y)\n",
        "        y = self.relu(y)\n",
        "        y = self.linear2(y)\n",
        "        y = self.linear3(y)\n",
        "        return self.sigmoid(y)"
      ],
      "metadata": {
        "id": "WPEV5kKOhI8h"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "fd4c7401dd3f40fba0826eb719ab534d",
            "763bbd89770442e0b78c269f751872ad",
            "aecfaa6d826b474e917201815cbd8efe",
            "5a600ae49c394459ac492e3bf5e655cc",
            "3789f09d236249c7a0d361dda35357dd",
            "a6d5a01bcde1469db73d3b4b90a6f9e2",
            "565ed09e02be40039895258c9d66b81d",
            "bbcdb36da34c4325946d71706fb2d384",
            "df1aeb7ecc5849be8eafd0b246804655",
            "ef2152997a9e4ec899527c6001ed37f1",
            "b614433d24d1442db321b8332ec2711a",
            "d7fd5ff7fc634b57b9ef4e6ab7e77167",
            "81c1cebfc925417d8b1b4f28fd038c4e",
            "54706146ccf84dcf9a021f6f496d6ba3",
            "881e53cfe4c54a38975143c5b503a5f9",
            "39fc78579e314f558ab3e56ac3037780",
            "30d5131d273e41de9e2ec4bebb6ae16c",
            "4b2ad41d13064de788e46fa9fdd4c8a8",
            "098ef4d0c9fe4c99b049a87c4aebc3ee",
            "9b642d1c7fde49cda0830cdc0c49ab11",
            "67c2894875b74de0ab2b6cb57db572c5",
            "0cddc68edeb243299b1755bfddb0d087",
            "c062f017da604a2c852480accb04b0f1",
            "26ac7a56d78a4278b3a336b09d72aafb",
            "0744edaff75e4576b8ccdc102ddcf295",
            "1d10146f753c48b9b8d027b8fc62a8a7",
            "dce823bcfa3148b8a28b76e30c46d912",
            "c954ae848359400e955fd3c22da876b9",
            "181a5a046a714edcaf9cc8a2be4fdee0",
            "26711ad4fc1042db806ff6e505a8105f",
            "e750aa308c884e41bd5a37ef1ec99267",
            "89f2bbf22fdf476faab98a11f8c4c960",
            "7a389080ff684c69bae01324e01117fc"
          ]
        },
        "id": "OJdsCzCuqzHQ",
        "outputId": "42c56ec1-47f3-4f70-8d4d-50fd2960d012"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd4c7401dd3f40fba0826eb719ab534d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/285 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7fd5ff7fc634b57b9ef4e6ab7e77167"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/16.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c062f017da604a2c852480accb04b0f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda'\n",
        "\n",
        "import numpy as np\n",
        "item_text_embeddings_size = 128\n",
        "user_embeddings_size = 100\n",
        "item_embeddings_size = 10#128\n",
        "text_col = 'tags'#abstract'\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME) \n",
        "dataset_train= LFM2bDataset(data_interaction_train,tokenizer,item_text_embeddings_size, text_col,  item2pos, user2id)\n",
        "dataset_val= LFM2bDataset(data_interaction_val,tokenizer,item_text_embeddings_size, text_col,  item2pos, user2id)\n",
        "\n",
        "# dataset_train= LFM2bDatasetMulitpleText(data_interaction_train,tokenizer,item_text_embeddings_size,  item2pos, user2id)\n",
        "# dataset_val= LFM2bDatasetMulitpleText(data_interaction_val,tokenizer,item_text_embeddings_size,  item2pos, user2id)\n",
        "\n",
        "num_users = len(data_interaction[user_col].drop_duplicates())\n",
        "num_items = len(pos2item)\n",
        "\n",
        "# hidden_dense_layer_size_base = item_embeddings_size + user_embeddings_size\n",
        "# model_base = AMARBase(hidden_dense_layer_size_base, item_embeddings_size, user_embeddings_size, num_users, num_items)\n",
        "\n",
        "# hidden_dense_layer_size_bert = item_embeddings_size + 2 * item_text_embeddings_size + user_embeddings_size\n",
        "# model_bert = AMARBertMultiple( hidden_dense_layer_size_bert, item_embeddings_size, user_embeddings_size, item_text_embeddings_size, num_users, num_items)\n",
        "\n",
        "# hidden_dense_layer_size_bert = item_embeddings_size + item_text_embeddings_size + user_embeddings_size\n",
        "# model_bert = AMARBert( hidden_dense_layer_size_bert, item_embeddings_size, user_embeddings_size, item_text_embeddings_size, num_users, num_items)\n",
        "\n",
        "hidden_dense_layer_size_bert = user_embeddings_size  +item_text_embeddings_size \n",
        "model = AMARBert(hidden_dense_layer_size_bert, user_embeddings_size, num_users)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = f\"./results/input_{text_col}_userEmb_optim_rms_model_{MODEL_NAME}/\"\n",
        "import os\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "WADY4G4HNmrP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJz9Z9f38MQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed7e55c-228d-4538-ef84-e4b93c0a0b7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saving best model for epoch: 0\n",
            "\n",
            "Epoch 0 | Average loss per epoch: Train: 0.6937558399735864 , Val: 0.6947466106932672, NDCG: 0.5497319781396682\n",
            "\n",
            "Saving best model for epoch: 1\n",
            "\n",
            "Epoch 1 | Average loss per epoch: Train: 0.6921485083705329 , Val: 0.6996689930436064, NDCG: 0.5508217084029948\n"
          ]
        }
      ],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "num_epochs=15\n",
        "batch_size=32\n",
        "\n",
        "dataloader_train=DataLoader(dataset=dataset_train,batch_size=batch_size, num_workers=4)\n",
        "dataloader_val=DataLoader(dataset=dataset_val,batch_size=batch_size, num_workers=4)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "lr = 1e-3\n",
        "num_total_steps = len(dataset_train) * num_epochs\n",
        "num_warmup_steps = 0\n",
        "warmup_proportion = float(num_warmup_steps) / float(num_total_steps)  \n",
        "optimizer =  torch.optim.RMSprop(model.parameters(), lr= lr, alpha=0.9)\n",
        "#optimizer = torch.optim.AdamW(model.parameters(), lr=lr)#, correct_bias=False)  \n",
        "\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "   optimizer,\n",
        "   num_warmup_steps=num_warmup_steps,\n",
        "   num_training_steps=num_total_steps\n",
        ")\n",
        "\n",
        "\n",
        "loss_train = []\n",
        "loss_val = []\n",
        "ndcg_val = []\n",
        "\n",
        "best_ndcg = 0\n",
        "cnt = 0\n",
        "\n",
        "for e in range(num_epochs):\n",
        "\n",
        "    losses_train = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for data_train in dataloader_train:\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        model.zero_grad()\n",
        "        #items positions\n",
        "        curr_items_ids_batch = data_train['track_id']\n",
        "        # items descriptions\n",
        "        curr_items_batch = data_train['input_ids_lyrics']\n",
        "        curr_attentions_batch = data_train['attention_mask_lyrics']\n",
        "\n",
        "        # additional items descriptions\n",
        "        # curr_items_batch1 = data_train['input_ids_tags']\n",
        "        # curr_attentions_batch1 = data_train['attention_mask_tags']\n",
        "        \n",
        "        # users ids\n",
        "        curr_users_batch =data_train['user_id']\n",
        "\n",
        "        # model inputs\n",
        "        inputs = [curr_items_ids_batch.type(torch.LongTensor).to(device), curr_items_batch.type(torch.LongTensor).to(device), \n",
        "                  curr_users_batch.type(torch.LongTensor).to(device), curr_attentions_batch.type(torch.LongTensor).to(device),\n",
        "                  # curr_items_batch1.type(torch.LongTensor).to(device),  curr_attentions_batch1.type(torch.LongTensor).to(device)\n",
        "                  ]\n",
        "\n",
        "        # model targets\n",
        "        targets = data_train['target'].reshape(-1,1)\n",
        "\n",
        "        # backward propagation\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, targets.to(device))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        # evaluate current loss function value\n",
        "        losses_train.append(loss.item())\n",
        "\n",
        "    # compute loss on validation set\n",
        "    model.eval()\n",
        "\n",
        "    losses_val = []\n",
        "\n",
        "    res = pd.DataFrame(columns = ['user_id', 'track_id', 'count'])\n",
        "    for data_val in dataloader_val:\n",
        "      gc.collect()\n",
        "      torch.cuda.empty_cache()\n",
        "      #items positions\n",
        "      curr_items_ids_batch = data_val['track_id']\n",
        "      # items descriptions\n",
        "      curr_items_batch = data_val['input_ids_lyrics']\n",
        "      curr_attentions_batch = data_val['attention_mask_lyrics']\n",
        "\n",
        "      # additional items descriptions\n",
        "      # curr_items_batch1 = data_val['input_ids_tags']\n",
        "      # curr_attentions_batch1 = data_val['attention_mask_tags']\n",
        "      \n",
        "      # users ids\n",
        "      curr_users_batch =data_val['user_id']\n",
        "\n",
        "      # model inputs\n",
        "      inputs = [curr_items_ids_batch.type(torch.LongTensor).to(device), \n",
        "                curr_items_batch.type(torch.LongTensor).to(device), \n",
        "                curr_users_batch.type(torch.LongTensor).to(device), \n",
        "                curr_attentions_batch.type(torch.LongTensor).to(device),\n",
        "                # curr_items_batch1.type(torch.LongTensor).to(device), \n",
        "                # curr_attentions_batch1.type(torch.LongTensor).to(device)\n",
        "                ]\n",
        "\n",
        "      # model targets\n",
        "      targets = data_val['target'].reshape(-1,1)\n",
        "\n",
        "      with torch.no_grad():        \n",
        "        outputs_val = model(inputs)\n",
        "\n",
        "      loss = criterion(outputs_val, targets.to(device))\n",
        "      losses_val.append(loss.item())\n",
        "\n",
        "      for i in range(outputs_val.shape[0]):\n",
        "        res = res.append(pd.DataFrame({'user_id': id2user[curr_users_batch[i].item()], 'track_id': pos2item[curr_items_ids_batch[i].item()], 'count':  outputs_val[i].item()} , index=[0]))\n",
        "\n",
        "    # compute ndcg for each user\n",
        "    ndcg = []\n",
        "    for user, df in res.groupby(user_col):\n",
        "      df = df.drop_duplicates(subset=item_col).sort_values('count', ascending=False)\n",
        "      y_true_sorted = data_interaction_val.loc[data_interaction_val[user_col] == user].sort_values(rating_col, ascending=False).drop_duplicates()\n",
        "      rel_pred = pd.merge(df[[item_col]], y_true_sorted[[item_col, rating_col]].drop_duplicates(), 'left').fillna(0)['count'].values\n",
        "      ndcg.append(get_ndcg(df, rel_pred, 10))\n",
        "\n",
        "    ndcg_e = np.mean(ndcg)\n",
        "    \n",
        "    # save best model based on ndcg\n",
        "    if ndcg_e > best_ndcg:\n",
        "      best_ndcg = ndcg_e\n",
        "      print(f\"\\nSaving best model for epoch: {e}\\n\")\n",
        "      torch.save(model.state_dict(), model_dir + 'best_model.pth')\n",
        "      cnt = 0\n",
        "    else:\n",
        "      cnt = cnt+1\n",
        "    if cnt > 4:\n",
        "      break\n",
        "\n",
        "    average_los_val = np.mean(losses_val)\n",
        "    loss_val.append(average_los_val.item())    \n",
        "    ndcg_val.append(ndcg_e)\n",
        "   \n",
        "    # evaluate average cost per epoch\n",
        "    average_loss_train = np.mean(losses_train)\n",
        "    loss_train.append(average_loss_train.item())\n",
        "    print(f\"Epoch {e} | Average loss per epoch: Train: {average_loss_train.item()} , Val: {average_los_val.item()}, NDCG: {ndcg_e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfR4uzskpgFt"
      },
      "outputs": [],
      "source": [
        "plt.plot(ndcg_val)\n",
        "plt.title(\"Validation NDCG@10\")\n",
        "\n",
        "#from google.colab import files\n",
        "plt.savefig(model_dir + \"ndcg.png\")\n",
        "#files.download(model_dir + \"ndcg.png\") "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_train, label='train')\n",
        "plt.plot(loss_val, label='val')\n",
        "plt.legend()\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "\n",
        "#from google.colab import files\n",
        "plt.savefig(model_dir + \"loss.png\")\n",
        "#files.download(model_dir + \"loss.png\") "
      ],
      "metadata": {
        "id": "ol3t_0CLJ0jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH1Njid6OwL8"
      },
      "source": [
        "## **BERT**: Get predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCUid5ff91xI"
      },
      "outputs": [],
      "source": [
        "batch_size= 32\n",
        "res = pd.DataFrame(columns = ['user_id', 'track_id', 'count'])\n",
        "dataset_test= LFM2bDataset(data_interaction_test,tokenizer,item_text_embeddings_size, text_col,  item2pos, user2id)\n",
        "# dataset_test= LFM2bDatasetMulitpleText(data_interaction_test,tokenizer,item_text_embeddings_size,  item2pos, user2id)\n",
        "dataloader_test=DataLoader(dataset=dataset_test,batch_size=batch_size, num_workers=4)\n",
        "\n",
        "#model = AMARBert( hidden_dense_layer_size_bert, item_embeddings_size, user_embeddings_size, item_text_embeddings_size, num_users, num_items)\n",
        "#model.load_state_dict(torch.load(model_dir + 'best_model.pth'))\n",
        "#model.to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "for data in dataloader_test:\n",
        "      gc.collect()\n",
        "      torch.cuda.empty_cache()\n",
        "      #items positions\n",
        "      curr_items_ids_batch = data['track_id']\n",
        "      # items descriptions\n",
        "      curr_items_batch = data['input_ids_lyrics']\n",
        "      curr_attentions_batch = data['attention_mask_lyrics']\n",
        "\n",
        "      # additional items descriptions\n",
        "      # curr_items_batch1 = data['input_ids_tags']\n",
        "      # curr_attentions_batch1 = data['attention_mask_tags']\n",
        "      \n",
        "      # users ids\n",
        "      curr_users_batch =data['user_id']\n",
        "\n",
        "      # model inputs\n",
        "      inputs = [curr_items_ids_batch.type(torch.LongTensor).to(device), \n",
        "                curr_items_batch.type(torch.LongTensor).to(device), \n",
        "                curr_users_batch.type(torch.LongTensor).to(device), \n",
        "                curr_attentions_batch.type(torch.LongTensor).to(device),\n",
        "                # curr_items_batch1.type(torch.LongTensor).to(device), \n",
        "                # curr_attentions_batch1.type(torch.LongTensor).to(device),\n",
        "                ]\n",
        "\n",
        "\n",
        "      with torch.no_grad():\n",
        "        outputs = model(inputs)\n",
        "\n",
        "\n",
        "      # save prediction for each user\n",
        "      for i in range(outputs.shape[0]):\n",
        "\n",
        "        res = res.append(pd.DataFrame({'user_id': id2user[curr_users_batch[i].item()], 'track_id': pos2item[curr_items_ids_batch[i].item()], 'count':  outputs[i].item()} , index=[0]))\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fg8zOdRZC-dh"
      },
      "outputs": [],
      "source": [
        "res[(res.user_id == 1120)].sort_values('count', ascending = False)#.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4js443_OgVB"
      },
      "outputs": [],
      "source": [
        "res[res.user_id == 546].sort_values('count', ascending = False)#.head(10) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFCptP7OEtI5"
      },
      "outputs": [],
      "source": [
        "topn=100\n",
        "results = []\n",
        "results_df = pd.DataFrame(columns = [user_col, item_col, rating_col])\n",
        "\n",
        "for user, user_prediction in res.groupby('user_id'):\n",
        "    results_df = results_df.append(user_prediction.sort_values('count', ascending=False).head(topn))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.to_csv(model_dir + 'predictions.csv', encoding = 'utf-8-sig') "
      ],
      "metadata": {
        "id": "D-dWSMgqNu_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c67LS6n1Y-A"
      },
      "source": [
        "# Most popular recommendation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyWJBqGz1blh"
      },
      "outputs": [],
      "source": [
        "topn = 100\n",
        "\n",
        "item_popularity_df = data_interaction_test.groupby(item_col)[rating_col].sum().sort_values(ascending=False).reset_index()\n",
        "\n",
        "predictions = {}\n",
        "\n",
        "for real_user_id in data_interaction_test.user_id.unique():\n",
        "    predictions[real_user_id] = []\n",
        "    items_to_ignore = data_interaction_train[data_interaction_train[user_col] == real_user_id]['track_id'].values\n",
        "    item_popularity_df_user = item_popularity_df[~item_popularity_df[item_col].isin(items_to_ignore)]\n",
        "    predictions[real_user_id].append(item_popularity_df_user.head(topn)[item_col].values.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQ51-oYe1djY"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "results_df = pd.DataFrame(columns = [user_col, item_col, rating_col])\n",
        "\n",
        "for user in predictions:\n",
        "    user_prediction = predictions[user][0]\n",
        "    for item in user_prediction:\n",
        "        rating = 1.\n",
        "        results_df = pd.concat((results_df, pd.DataFrame(data={user_col:[user],item_col:[item],rating_col:[rating]})))\n",
        "        results.append([user, item, rating])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-A_VQKP1hFS"
      },
      "source": [
        "# Random recommendation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68Z2iimV1pAk"
      },
      "outputs": [],
      "source": [
        "topn = 100\n",
        "\n",
        "predictions = {}\n",
        "\n",
        "for real_user_id in data_interaction_test.user_id.unique():\n",
        "    predictions[real_user_id] = []\n",
        "    items_to_ignore = data_interaction_train[data_interaction_train[user_col] == real_user_id][item_col].values\n",
        "    item_df_user = data_interaction_test[~data_interaction_test[item_col].isin(items_to_ignore)]\n",
        "    predictions[real_user_id].append(random.sample(set(item_df_user['track_id'].values), topn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6xHh03Y1qFu"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "results_df = pd.DataFrame(columns = [user_col, item_col, rating_col])\n",
        "\n",
        "for user in predictions:\n",
        "    user_prediction = predictions[user][0]\n",
        "    for item in user_prediction:\n",
        "        rating = 1.\n",
        "        results_df = pd.concat((results_df, pd.DataFrame(data={user_col:[user],item_col:[item],rating_col:[rating]})))\n",
        "        results.append([user, item, rating])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxzLZWaLAhUZ"
      },
      "source": [
        "# Evaluate predictions\n",
        "\n",
        "Scores: F1@10, ndcg@k, recall@k"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topn=100"
      ],
      "metadata": {
        "id": "XS-AQqs-iXDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-T1kV_Wk5as"
      },
      "outputs": [],
      "source": [
        "#results_df = pd.read_csv(model_dir + \"predictions.csv\").drop([\"Unnamed: 0\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DTstEsi72xS"
      },
      "outputs": [],
      "source": [
        "f1_scores = []\n",
        "recall_scores = []\n",
        "ndcg_scores = []\n",
        "\n",
        "for user, df in results_df.groupby(user_col):\n",
        "  df = df.drop_duplicates(subset=item_col)\n",
        "\n",
        "  y_true_sorted = data_interaction_test.loc[data_interaction_test[user_col] == user].sort_values(rating_col, ascending=False).drop_duplicates()\n",
        "  rel = pd.merge(df[[item_col]], y_true_sorted[[item_col, rating_col]].drop_duplicates(), 'left').fillna(0)['count'].values\n",
        "  y_true_df = pd.merge(data_items_eval[[item_col]].drop_duplicates(), y_true_sorted[[item_col, rating_col]].drop_duplicates(), 'left').fillna(0)\n",
        "  y_true_ndcg = y_true_df[rating_col].values\n",
        "  y_true_df.loc[y_true_df[rating_col] > 0, rating_col] = 1\n",
        "  y_true = y_true_df[rating_col].values\n",
        "\n",
        "  y_pred_df = pd.merge(data_items_eval[[item_col]].drop_duplicates(), df[[item_col, rating_col]], 'left').fillna(0)\n",
        "  y_pred_ndcg = y_pred_df[rating_col].values\n",
        "  y_pred_df.loc[y_pred_df[rating_col] > 0, rating_col] = 1\n",
        "  y_pred = y_pred_df[rating_col].values\n",
        "\n",
        "  if y_true.sum() >= 1:\n",
        "    f1_scores.append(f1_score(y_true, y_pred))\n",
        "    recall_scores.append(recall_score(y_true, y_pred))\n",
        "    ndcg_scores.append(get_ndcg(df, rel, topn))\n",
        "\n",
        "print(\"F1 Score: \", np.mean(f1_scores))\n",
        "print(\"Recall Score: \", np.mean(recall_scores))\n",
        "print(\"NDCG Score: \", np.mean(ndcg_scores))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({\"f1_score\": [np.mean(f1_scores)], 'recall': [np.mean(recall_scores)], 'ndcg': [np.mean(ndcg_scores)]}).to_csv(model_dir + 'evaluation_result.csv', encoding = 'utf-8-sig') "
      ],
      "metadata": {
        "id": "FVnaLOPiPmsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaONzUp8rsKH"
      },
      "source": [
        "# Interpretability of Gender Bias\n",
        "\n",
        "- Find correlations between user gender and item gender (Pearsons correlation)\n",
        "- For each track get proportion of female/male user => compare train and recommendataion data\n",
        "- Check if genderness increased/decreased in recommendations (in comparision to training data) \n",
        "- Compare distribution of genderness between history and recommendations \n",
        "  - \"Delta Metric of Genderness\" (https://arxiv.org/pdf/2108.06973.pdf)\n",
        "  - Proportion tests: Fisher exact test, Chi-Square\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get feature vectors"
      ],
      "metadata": {
        "id": "0oWwJyvwn2z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feature_vector(model, inputs, batch_size):\n",
        "\n",
        "  layer = model._modules.get('model1_layer3')\n",
        "\n",
        "  embedding = torch.zeros((batch_size, 128))\n",
        "  def copy_data(m, i, o):\n",
        "          embedding.copy_(o.data)\n",
        "  h = layer.register_forward_hook(copy_data)\n",
        "  model(inputs)\n",
        "  h.remove()\n",
        "  return embedding"
      ],
      "metadata": {
        "id": "9qoYc5VwgnWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_vectors = pd.DataFrame()\n",
        "batch_size= 12\n",
        "dataset_test= LFM2bDataset(data_interaction_test,tokenizer,item_text_embeddings_size, text_col,  item2pos, user2id)\n",
        "#dataset_test= LFM2bDatasetMulitpleText(data_interaction_test,tokenizer,item_text_embeddings_size,  item2pos, user2id)\n",
        "dataloader_test=DataLoader(dataset=dataset_test,batch_size=batch_size, num_workers=4)\n",
        "\n",
        "#model = AMARBert( hidden_dense_layer_size_bert, item_embeddings_size, user_embeddings_size, item_text_embeddings_size, num_users, num_items)\n",
        "#model.load_state_dict(torch.load(model_dir + 'best_model.pth'))\n",
        "#model.to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "for data in dataloader_test:\n",
        "  #items positions\n",
        "  curr_items_ids_batch = data['track_id']\n",
        "  # items descriptions\n",
        "  curr_items_batch = data['input_ids_lyrics']\n",
        "  curr_attentions_batch = data['attention_mask_lyrics']\n",
        "\n",
        "  # additional items descriptions\n",
        "  # curr_items_batch1 = data['input_ids_tags']\n",
        "  # curr_attentions_batch1 = data['attention_mask_tags']\n",
        "\n",
        "  # users ids\n",
        "  curr_users_batch =data['user_id']\n",
        "\n",
        "  # model inputs\n",
        "  inputs = [curr_items_ids_batch.type(torch.LongTensor).to(device), \n",
        "            curr_items_batch.type(torch.LongTensor).to(device), \n",
        "            curr_users_batch.type(torch.LongTensor).to(device), \n",
        "            curr_attentions_batch.type(torch.LongTensor).to(device),\n",
        "            # curr_items_batch1.type(torch.LongTensor).to(device), \n",
        "            # curr_attentions_batch1.type(torch.LongTensor).to(device),\n",
        "            ]\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    \n",
        "  # save embedding layer for each item\n",
        "\n",
        "  # save prediction for each user\n",
        "  item_list=[]\n",
        "  for i in range(outputs.shape[0]):\n",
        "    item_list.append(pos2item[curr_items_ids_batch[i].item()])\n",
        "    \n",
        "  feature_vector = get_feature_vector(model, inputs, batch_size)\n",
        "  fv = pd.DataFrame(feature_vector)\n",
        "  fv.index = item_list\n",
        "  feature_vectors = feature_vectors.append(fv)\n",
        "  break\n",
        "      "
      ],
      "metadata": {
        "id": "jcBP8cIYn2Tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_vectors"
      ],
      "metadata": {
        "id": "aMtoySmyiBw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc6rPo1eHeca"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Master\\ Thesis/data"
      ],
      "metadata": {
        "id": "dsKX_3D7mLY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_predictions = pd.read_csv(\"predictions_lyrics_tags.csv\").drop(['Unnamed: 0'],axis=1)\n",
        "topn=100\n",
        "results = []\n",
        "results_df = pd.DataFrame(columns = [user_col, item_col, rating_col])\n",
        "\n",
        "for user, user_prediction in data_predictions.groupby('user_id'):\n",
        "    results_df = results_df.append(user_prediction.sort_values('count', ascending=False).head(topn))\n",
        "    "
      ],
      "metadata": {
        "id": "PEoc663Hhm44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1AXovkyepH2"
      },
      "outputs": [],
      "source": [
        "data_interaction_new = results_df.merge(data_items_eval, on = 'track_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkwEcnpNe-Tp"
      },
      "outputs": [],
      "source": [
        "data_interaction_new[data_interaction_new.user_id == 119741]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E333xxdQfJs2"
      },
      "outputs": [],
      "source": [
        "data_all_info = pd.read_csv(\"music/data_all_info.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_all_info = data_all_info[['track_artist', 'gender_artist', 'track_id']]"
      ],
      "metadata": {
        "id": "nq6IgVRlmhb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wx9d2jqQfZ6M"
      },
      "outputs": [],
      "source": [
        "data_user = pd.read_csv(\"data_user.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)\n",
        "data_user.columns = ['user_id', 'gender_user']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_classification = data_all_info\n",
        "replace_dict1 = {'m' : 0, 'f' : 1}\n",
        "replace_dict2 = {'male' : 0, 'female' : 1}\n",
        "#data_classification['gender_user'] = data_classification['gender_user'].replace(replace_dict1)\n",
        "data_classification['gender_artist'] = data_classification['gender_artist'].replace(replace_dict2)\n",
        "data_classification = data_classification.merge(data_tracks_tags_lyrics[['track_id', 'tags', 'abstract']], on = 'track_id')\n",
        "data_classification"
      ],
      "metadata": {
        "id": "qc96JC7pl0sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXxzbJOlgRhp"
      },
      "outputs": [],
      "source": [
        "df_tmp = pd.merge(data_interaction_train, data_user, 'inner')\n",
        "df_all = pd.merge(df_tmp, data_all_info, on = 'track_id').drop_duplicates()\n",
        "\n",
        "replace_dict1 = {'m' : 0, 'f' : 1}\n",
        "replace_dict2 = {'male' : 0, 'female' : 1}\n",
        "df_all['gender_user'] = df_all['gender_user'].replace(replace_dict1)\n",
        "df_all['gender_artist'] = df_all['gender_artist'].replace(replace_dict2)\n",
        "\n",
        "df_train = df_all[df_all['count'] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dewGb1xmPBXN"
      },
      "outputs": [],
      "source": [
        "df_tmp = pd.merge(data_interaction_test, data_user, 'inner')\n",
        "df_all = pd.merge(df_tmp, data_all_info, on = 'track_id').drop_duplicates()\n",
        "\n",
        "replace_dict1 = {'m' : 0, 'f' : 1}\n",
        "replace_dict2 = {'male' : 0, 'female' : 1}\n",
        "df_all['gender_user'] = df_all['gender_user'].replace(replace_dict1)\n",
        "df_all['gender_artist'] = df_all['gender_artist'].replace(replace_dict2)\n",
        "\n",
        "df_test = df_all[df_all['count'] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WYe_kSEhSTl"
      },
      "outputs": [],
      "source": [
        "df_tmp = pd.merge(results_df, data_user, 'inner')\n",
        "df_all = pd.merge(df_tmp, data_all_info, on = 'track_id').drop_duplicates()\n",
        "\n",
        "replace_dict1 = {'m' : 0, 'f' : 1}\n",
        "replace_dict2 = {'male' : 0, 'female' : 1}\n",
        "df_all['gender_user'] = df_all['gender_user'].replace(replace_dict1)\n",
        "df_all['gender_artist'] = df_all['gender_artist'].replace(replace_dict2)\n",
        "\n",
        "df_rec = df_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfJvYiuFjQ54"
      },
      "source": [
        "## Distribution of gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty8fFzv_jQiN"
      },
      "outputs": [],
      "source": [
        "print(f\"In the history data, {round(df_train.gender_artist.sum() / len(df_train) * 100, 2)} % female items were consumed.\")\n",
        "print(f\"In the test data, {round(df_test.gender_artist.sum() / len(df_test) * 100, 2)} % female items were consumed.\")\n",
        "print(f\"In the recommendation data, {round(df_rec.gender_artist.sum() / len(df_rec) * 100, 2)} % female items were recommended.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgDbgyUFYVPF"
      },
      "source": [
        "## Correlation between user and item gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4aOub4YUaga"
      },
      "outputs": [],
      "source": [
        "# Proportion of female items in all female user\n",
        "prop_female = 0\n",
        "# Proportion of female items in all male user\n",
        "prop_male = 0\n",
        "for group, df in df_train.groupby('gender_user'):\n",
        "  if group == 0:\n",
        "    prop_male = df.gender_artist.sum() / len(df)\n",
        "  else:\n",
        "    prop_female = df.gender_artist.sum() / len(df)\n",
        "\n",
        "print(f'In the history data, all female users listen to {round(prop_female*100, 2)} % female items.')\n",
        "print(f'In the history data, all male users listen to {round(prop_male*100, 2)} % female items.')\n",
        "\n",
        "# Phi correlation (http://web.pdx.edu/~newsomj/pa551/lectur15.htm)\n",
        "print('The attributes gender_user and gender_artist show a correlation of ', df_train.gender_user.corr(df_train.gender_artist))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eFAQadph9Yz"
      },
      "outputs": [],
      "source": [
        "# Proportion of female items in all female user\n",
        "prop_female = 0\n",
        "# Proportion of female items in all male user\n",
        "prop_male = 0\n",
        "for group, df in df_rec.groupby('gender_user'):\n",
        "  if group == 0:\n",
        "    prop_male = df.gender_artist.sum() / len(df)\n",
        "  else:\n",
        "    prop_female = df.gender_artist.sum() / len(df)\n",
        "\n",
        "print(f'In the recommendation data, to all female users {round(prop_female*100, 2)} % female items are recommended.')\n",
        "print(f'In the recommendation data, to all male users {round(prop_male*100, 2)} % female items are recommended.')\n",
        "\n",
        "# Phi correlation\n",
        "print('The attributes gender_user and gender_artist show a correlation of ', df_rec.gender_user.corr(df_rec.gender_artist))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEiaFN1bYdFE"
      },
      "source": [
        "## Delta metric of genderness\n",
        "\n",
        " For user u_i: (prop_female(rec) - prop_female(history)) / prop_female(history)\n",
        "\n",
        " If positive: more female tracks are recommended to the user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JP_j3yQgd6Gx"
      },
      "outputs": [],
      "source": [
        "prop_female_rec = df_rec.gender_artist.sum() / len(df_rec)\n",
        "prop_female_history = df_train.gender_artist.sum() / len(df_train)\n",
        "delta = (prop_female_rec - prop_female_history) / prop_female_history\n",
        "\n",
        "if delta > 0:\n",
        "  print(f'The value of delta is {round(delta, 4)} and therefore more female tracks are recommended to user.')\n",
        "else:\n",
        "  print(f'The value of delta is {round(delta, 4)} and therefore more male tracks are recommended to user.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W5yg61kZJOV"
      },
      "source": [
        "## Proportion distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IV5pBGTjYfsO"
      },
      "outputs": [],
      "source": [
        "prop_all = []\n",
        "prop_male = []\n",
        "prop_female = []\n",
        "for user, df in df_train.groupby('user_id'):\n",
        "  p = df.gender_artist.sum() / len(df)\n",
        "  prop_all.append(p)\n",
        "  if (df.gender_user).all() == 0:\n",
        "    prop_male.append(p)\n",
        "  else: prop_female.append(p)\n",
        "\n",
        "print(f\"In the history data, there were on average {round(np.mean(prop_all)*100, 2)} % female items consumed.\")\n",
        "print(f\"In the history data, among all male users there were on average {round(np.mean(prop_male)*100, 2)} % female items consumed.\")\n",
        "print(f\"In the history data, among all female users there were on average {round(np.mean(prop_female)*100, 2)} % female items consumed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikI_8GX1k2lI"
      },
      "outputs": [],
      "source": [
        "prop_all = []\n",
        "prop_male = []\n",
        "prop_female = []\n",
        "for user, df in df_rec.groupby('user_id'):\n",
        "  p = df.gender_artist.sum() / len(df)\n",
        "  prop_all.append(p)\n",
        "  if (df.gender_user).all() == 0:\n",
        "    prop_male.append(p)\n",
        "  else: prop_female.append(p)\n",
        "\n",
        "print(f\"In the recommendation data, there are on average {round(np.mean(prop_all)*100, 2)} % female items recommended.\")\n",
        "print(f\"In the recommendation data, among all male users there are on average {round(np.mean(prop_male)*100, 2)} % female items recommended.\")\n",
        "print(f\"In the recommendation data, among all female users there are on average {round(np.mean(prop_female)*100, 2)} % female items recommended.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjjmSaKW-99W"
      },
      "source": [
        "# BERT classification model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF1vpMAVGwwQ"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/Colab\\ Notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj90aXI0_BYc"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from smooth_gradient import SmoothGradient\n",
        "from integrated_gradient import IntegratedGradient\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DistilBertConfig, DistilBertTokenizer\n",
        "from transformers import BertTokenizer, BertModel, AdamW\n",
        "\n",
        "from IPython.display import display, HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR_66w52_s_4"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class ArtistDataset(Dataset):\n",
        "    def __init__(self, data_all,tokenizer,max_length, text_col):\n",
        "        super(ArtistDataset, self).__init__()\n",
        "        self.data_all = data_all\n",
        "        self.max_length = max_length\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text_col = text_col\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data_all)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        text1 = self.data_all.iloc[index][self.text_col]\n",
        "        \n",
        "        inputs = tokenizer.encode_plus(\n",
        "            text1, \n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length = self.max_length,\n",
        "            pad_to_max_length=True\n",
        "            \n",
        "        )\n",
        "        ids = inputs[\"input_ids\"]\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "        mask = inputs[\"attention_mask\"]\n",
        "\n",
        "        return {\n",
        "            'input_ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'target': torch.tensor(self.data_all.iloc[index]['gender_artist'], dtype=torch.float)\n",
        "            }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJyXCdXwSd_D"
      },
      "outputs": [],
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "  def __init__(self, n_classes=2):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained('prajjwal1/bert-tiny')\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    y, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask, return_dict=False\n",
        "    )\n",
        "    pooled_output = y[:,0,:]\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWIGzeWVSpea"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class SaliencyInterpreter:\n",
        "    def __init__(self,\n",
        "                 model,\n",
        "                 criterion,\n",
        "                 tokenizer,\n",
        "                 show_progress=True,\n",
        "                 **kwargs):\n",
        "\n",
        "        \"\"\"\n",
        "        :param model: nn.Module object - can be HuggingFace's model or custom one.\n",
        "        :param criterion: torch criterion used to train your model.\n",
        "        :param tokenizer: HuggingFace's tokenizer.\n",
        "        :param show_progress: bool flag to show tqdm progress bar.\n",
        "        :param kwargs:\n",
        "            encoder: string indicates the HuggingFace's encoder, that has 'embeddings' attribute. Used\n",
        "                if your model doesn't have 'get_input_embeddings' method to get access to encoder embeddings\n",
        "        \"\"\"\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model = model.to(self.device)\n",
        "        self.model.eval()\n",
        "        self.criterion = criterion\n",
        "        self.tokenizer = tokenizer\n",
        "        self.show_progress = show_progress\n",
        "        self.kwargs = kwargs\n",
        "        # to save outputs in saliency_interpret\n",
        "        self.batch_output = None\n",
        "\n",
        "    def _get_gradients(self, batch):\n",
        "        # set requires_grad to true for all parameters, but save original values to\n",
        "        # restore them later\n",
        "        original_param_name_to_requires_grad_dict = {}\n",
        "        for param_name, param in self.model.named_parameters():\n",
        "            original_param_name_to_requires_grad_dict[param_name] = param.requires_grad\n",
        "            param.requires_grad = True\n",
        "        embedding_gradients = []\n",
        "        hooks = self._register_embedding_gradient_hooks(embedding_gradients)\n",
        "\n",
        "        loss = self.forward_step(batch)\n",
        "\n",
        "        self.model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        for hook in hooks:\n",
        "            hook.remove()\n",
        "\n",
        "        # restore the original requires_grad values of the parameters\n",
        "        for param_name, param in self.model.named_parameters():\n",
        "            param.requires_grad = original_param_name_to_requires_grad_dict[param_name]\n",
        "\n",
        "        return embedding_gradients[0]\n",
        "\n",
        "    def _register_embedding_gradient_hooks(self, embedding_gradients):\n",
        "        \"\"\"\n",
        "        Registers a backward hook on the\n",
        "        Used to save the gradients of the embeddings for use in get_gradients()\n",
        "        When there are multiple inputs (e.g., a passage and question), the hook\n",
        "        will be called multiple times. We append all the embeddings gradients\n",
        "        to a list.\n",
        "        \"\"\"\n",
        "\n",
        "        def hook_layers(module, grad_in, grad_out):\n",
        "            embedding_gradients.append(grad_out[0])\n",
        "\n",
        "        backward_hooks = []\n",
        "        embedding_layer = self.get_embeddings_layer()\n",
        "        backward_hooks.append(embedding_layer.register_backward_hook(hook_layers))\n",
        "        return backward_hooks\n",
        "\n",
        "    def get_embeddings_layer(self):\n",
        "        if hasattr(self.model, \"get_input_embeddings\"):\n",
        "            embedding_layer = self.model.get_input_embeddings()\n",
        "        else:\n",
        "            encoder_attribute = self.kwargs.get(\"encoder\")\n",
        "            assert encoder_attribute, \"Your model doesn't have 'get_input_embeddings' method, thus you \" \\\n",
        "                \"have provide 'encoder' key argument while initializing SaliencyInterpreter object\"\n",
        "            embedding_layer = getattr(self.model, encoder_attribute).embeddings\n",
        "        return embedding_layer\n",
        "\n",
        "    def colorize(self, instance, skip_special_tokens=False):\n",
        "\n",
        "        special_tokens = self.special_tokens\n",
        "\n",
        "        word_cmap = matplotlib.cm.Blues\n",
        "        prob_cmap = matplotlib.cm.Greens\n",
        "        template = '<span class=\"barcode\"; style=\"color: black; background-color: {}\">{}</span>'\n",
        "        colored_string = ''\n",
        "        # Use a matplotlib normalizer in order to make clearer the difference between values\n",
        "        normalized_and_mapped = matplotlib.cm.ScalarMappable(cmap=word_cmap).to_rgba(instance['grad'])\n",
        "        for word, color in zip(instance['tokens'], normalized_and_mapped):\n",
        "            if word in special_tokens and skip_special_tokens:\n",
        "                continue\n",
        "            # handle wordpieces\n",
        "            word = word.replace(\"##\", \"\") if \"##\" in word else ' ' + word\n",
        "            color = matplotlib.colors.rgb2hex(color[:3])\n",
        "            colored_string += template.format(color, word)\n",
        "        colored_string += template.format(0, \"    Label: {} |\".format(instance['label']))\n",
        "        prob = instance['prob']\n",
        "        color = matplotlib.colors.rgb2hex(prob_cmap(prob)[:3])\n",
        "        colored_string += template.format(color, \"{:.2f}%\".format(instance['prob']*100)) + '|'\n",
        "        return colored_string\n",
        "\n",
        "    @property\n",
        "    def special_tokens(self):\n",
        "        \"\"\"\n",
        "        Some tokenizers don't have 'eos_token' and 'bos_token' attributes.\n",
        "        So needed we some trick to get them.\n",
        "        \"\"\"\n",
        "        if self.tokenizer.bos_token is None or self.tokenizer.eos_token is None:\n",
        "            special_tokens = self.tokenizer.build_inputs_with_special_tokens([])\n",
        "            special_tokens_ids = self.tokenizer.convert_ids_to_tokens(special_tokens)\n",
        "            self.tokenizer.bos_token, self.tokenizer.eos_token = special_tokens_ids\n",
        "\n",
        "        special_tokens = self.tokenizer.eos_token, self.tokenizer.bos_token\n",
        "        return special_tokens\n",
        "\n",
        "    def forward_step(self, batch):\n",
        "        \"\"\"\n",
        "        If your model receive inputs in another way or you computing not\n",
        "         like in this example simply override this method. It should return the batch loss\n",
        "        :param batch: batch returned by dataloader\n",
        "        :return: torch.Tensor: batch loss\n",
        "        \"\"\"\n",
        "        input_ids = batch.get('input_ids').to(self.device)\n",
        "        attention_mask = batch.get(\"attention_mask\").to(self.device)\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        label = torch.argmax(outputs, dim=1)\n",
        "        batch_losses = self.criterion(outputs, label)\n",
        "        loss = torch.mean(batch_losses)\n",
        "\n",
        "        self.batch_output = [input_ids, outputs]\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def update_output(self):\n",
        "        \"\"\"\n",
        "        You can also override this method if you want to change the format\n",
        "         of outputs. (e.g. store just gradients)\n",
        "        :return: batch_output\n",
        "        \"\"\"\n",
        "\n",
        "        input_ids, outputs, grads = self.batch_output\n",
        "\n",
        "        probs = softmax(outputs, dim=-1)\n",
        "        probs, labels = torch.max(probs, dim=-1)\n",
        "\n",
        "        tokens = [\n",
        "            self.tokenizer.convert_ids_to_tokens(input_ids_)\n",
        "            for input_ids_ in input_ids\n",
        "        ]\n",
        "\n",
        "        embedding_grads = grads.sum(dim=2)\n",
        "        # norm for each sequence\n",
        "        norms = torch.norm(embedding_grads, dim=1, p=1)\n",
        "        # normalizing\n",
        "        for i, norm in enumerate(norms):\n",
        "            embedding_grads[i] = torch.abs(embedding_grads[i]) / norm\n",
        "\n",
        "        batch_output = []\n",
        "\n",
        "        iterator = zip(tokens, probs, embedding_grads, labels)\n",
        "\n",
        "        for example_tokens, example_prob, example_grad, example_label in iterator:\n",
        "            example_dict = dict()\n",
        "            # as we do it by batches we has a padding so we need to remove it\n",
        "            example_tokens = [t for t in example_tokens if t != self.tokenizer.pad_token]\n",
        "            example_dict['tokens'] = example_tokens\n",
        "            example_dict['grad'] = example_grad.cpu().tolist()[:len(example_tokens)]\n",
        "            example_dict['label'] = example_label.item()\n",
        "            example_dict['prob'] = example_prob.item()\n",
        "            batch_output.append(example_dict)\n",
        "        return batch_output\n",
        "\n",
        "import torch\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "class SmoothGradient(SaliencyInterpreter):\n",
        "    \"\"\"\n",
        "    Interprets the prediction using SmoothGrad (https://arxiv.org/abs/1706.03825)\n",
        "    Registered as a `SaliencyInterpreter` with name \"smooth-gradient\".\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 model,\n",
        "                 criterion,\n",
        "                 tokenizer,\n",
        "                 stdev=0.01,\n",
        "                 num_samples=20,\n",
        "                 show_progress=True,\n",
        "                 **kwargs):\n",
        "        super().__init__(model, criterion, tokenizer, show_progress, **kwargs)\n",
        "        # Hyperparameters\n",
        "        self.stdev = stdev\n",
        "        self.num_samples = num_samples\n",
        "\n",
        "    def saliency_interpret(self, test_dataloader):\n",
        "\n",
        "        instances_with_grads = []\n",
        "        iterator = tqdm(test_dataloader) if self.show_progress else test_dataloader\n",
        "\n",
        "        for batch in iterator:\n",
        "\n",
        "            # we will store there batch outputs such as gradients, probability, tokens\n",
        "            # so as each of them are used in different places, for convenience we will create\n",
        "            # it as attribute:\n",
        "            self.batch_output = []\n",
        "            self._smooth_grads(batch)\n",
        "            batch_output = self.update_output()\n",
        "            instances_with_grads.extend(batch_output)\n",
        "\n",
        "        return instances_with_grads\n",
        "\n",
        "    def _register_forward_hook(self, stdev: float):\n",
        "        \"\"\"\n",
        "        Register a forward hook on the embedding layer which adds random noise to every embedding.\n",
        "        Used for one term in the SmoothGrad sum.\n",
        "        \"\"\"\n",
        "\n",
        "        def forward_hook(module, inputs, output):\n",
        "            # Random noise = N(0, stdev * (max-min))\n",
        "            scale = output.detach().max() - output.detach().min()\n",
        "            noise = torch.randn(output.shape).to(output.device) * stdev * scale\n",
        "\n",
        "            # Add the random noise\n",
        "            output.add_(noise)\n",
        "\n",
        "        # Register the hook\n",
        "        embedding_layer = self.get_embeddings_layer()\n",
        "        handle = embedding_layer.register_forward_hook(forward_hook)\n",
        "        return handle\n",
        "\n",
        "    def _smooth_grads(self, batch):\n",
        "        total_gradients = None\n",
        "        for _ in range(self.num_samples):\n",
        "            handle = self._register_forward_hook(self.stdev)\n",
        "            grads = self._get_gradients(batch)\n",
        "            handle.remove()\n",
        "\n",
        "            # Sum gradients\n",
        "            if total_gradients is None:\n",
        "                total_gradients = grads\n",
        "            else:\n",
        "                total_gradients = total_gradients + grads\n",
        "\n",
        "        total_gradients /= self.num_samples\n",
        "\n",
        "        self.batch_output.append(total_gradients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKATY80EQhcn"
      },
      "outputs": [],
      "source": [
        "data_classification = data_classification.drop_duplicates()\n",
        "\n",
        "class_0 = data_classification[data_classification['gender_artist'] == 0]\n",
        "class_1 = data_classification[data_classification['gender_artist'] == 1]\n",
        "class_count_0, class_count_1 = data_classification['gender_artist'].value_counts()\n",
        "\n",
        "class_0_under = class_0.sample(class_count_1)\n",
        "test_under = pd.concat([class_0_under, class_1], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmkX_fFg_vyD"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') \n",
        "\n",
        "dataset_train= ArtistDataset(test_under,tokenizer, 128, 'lyrics_cleaned')\n",
        "\n",
        "dataloader_train=DataLoader(dataset=dataset_train,batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbhJiB2DcyPg"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "wgnJxoT5n77x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-O0hGQ33_yCm"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# model = BertForSequenceClassification.from_pretrained(\n",
        "#     'bert-base-uncased', \n",
        "#     num_labels = 2, \n",
        "#     output_attentions = False, \n",
        "#     output_hidden_states = False, \n",
        "# ).to(device)\n",
        "model = SentimentClassifier().to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plJ9-b0g_0Rn"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "epochs = 20\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "total_steps = len(dataloader_train) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    losses = []\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(dataloader_train):\n",
        "\n",
        "        b_input_ids = batch['input_ids'].to(device)\n",
        "        b_input_mask = batch['attention_mask'].to(device)\n",
        "        b_labels = batch['target'].type(torch.LongTensor).to(device)\n",
        "    \n",
        "\n",
        "        outputs = model(\n",
        "          input_ids=b_input_ids,\n",
        "          attention_mask=b_input_mask\n",
        "        )#['logits']\n",
        "\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "        loss = loss_fn(outputs, b_labels)\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        \n",
        "        scheduler.step()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "    print(f\"Epoch {epoch_i}, Loss {np.mean(losses)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "id": "acrNzDUDoqEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0Nd2qnP_5lv"
      },
      "outputs": [],
      "source": [
        "integrated_grad = SmoothGradient(\n",
        "    model, \n",
        "    loss_fn, \n",
        "    tokenizer, \n",
        "    show_progress=False,\n",
        "    encoder=\"bert\"\n",
        ")\n",
        "instances = integrated_grad.saliency_interpret(dataloader_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sacNXcd0KEpV"
      },
      "outputs": [],
      "source": [
        "words_male = []\n",
        "words_female = []\n",
        "for i in range(len(instances)):\n",
        "  idx = np.argsort(instances[i]['grad'])[::-1][:10]\n",
        "  if instances[i]['label'] == 0:\n",
        "    words_male = words_male + [instances[i]['tokens'][val] for val in idx]\n",
        "  else: \n",
        "    words_female = words_female + [instances[i]['tokens'][val] for val in idx]\n",
        "\n",
        "words_male = [ elem for elem in words_male if elem not in ['[SEP]', '[CLS]']]\n",
        "words_female = [ elem for elem in words_female if elem not in ['[SEP]', '[CLS]']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-iwKmY9dyT0"
      },
      "outputs": [],
      "source": [
        "len(words_male)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CPgQBRS_7ms"
      },
      "outputs": [],
      "source": [
        "coloder_string = integrated_grad.colorize(instances[1])\n",
        "display(HTML(coloder_string))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnwG--ONLiLM"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "#convert list to string and generate\n",
        "unique_string=(\" \").join(words_female)\n",
        "wordcloud = WordCloud(width = 1000, height = 500).generate(unique_string)\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "print(wordcloud.words_.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFWzsRuNXLYd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "#convert list to string and generate\n",
        "unique_string=(\" \").join(words_male)\n",
        "wordcloud = WordCloud(width = 1000, height = 500).generate(unique_string)\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "print(wordcloud.words_.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtIQzQEH2vhy"
      },
      "source": [
        "# Predict artist gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_NzF7QQ3J6Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FducXCFxKURy"
      },
      "outputs": [],
      "source": [
        "data_all_info = pd.read_csv(\"music/data_all_info.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "data_all_info = data_all_info.loc[data_all_info.artist_gender != 'other' ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XV1iDFGB0mF"
      },
      "outputs": [],
      "source": [
        "input = feature_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv1QvFM3I22n"
      },
      "outputs": [],
      "source": [
        "df_features = pd.DataFrame()\n",
        "id_col = []\n",
        "\n",
        "for id in data_interaction_test[item_col].unique():\n",
        "  id_col.append(id)\n",
        "  df_features = df_features.append(pd.DataFrame(input[id][0].detach().numpy()))\n",
        "\n",
        "df_features[item_col] = id_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBOE0G_TJ28n"
      },
      "outputs": [],
      "source": [
        "df_features = pd.merge(df_features, data_all_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOQ6VKT_IVyg"
      },
      "outputs": [],
      "source": [
        "df_features.loc[df_features.artist_gender == 'female', 'artist_gender'] = 0\n",
        "df_features.loc[df_features.artist_gender == 'male', 'artist_gender'] = 1\n",
        "df_features.artist_gender = df_features.artist_gender.astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ic2xa382unN"
      },
      "outputs": [],
      "source": [
        "X = df_features.iloc[:,:128]\n",
        "y = df_features.artist_gender\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.4, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h50TBcLs3G7l"
      },
      "outputs": [],
      "source": [
        "#clf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred=clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test.values, y_pred))\n",
        "print(\"Balanced Accuracy:\", metrics.balanced_accuracy_score(y_test.values, y_pred))\n",
        "print(\"Recall: \", metrics.recall_score(y_test.values, y_pred))\n",
        "print(\"Precision: \", metrics.precision_score(y_test.values, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQSgoDfe4Cc4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "feature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\n",
        "feature_imp.head(10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "0c67LS6n1Y-A",
        "K-A_VQKP1hFS",
        "jc6rPo1eHeca",
        "hgDbgyUFYVPF",
        "UEiaFN1bYdFE",
        "_W5yg61kZJOV",
        "xjjmSaKW-99W",
        "NtIQzQEH2vhy"
      ],
      "machine_shape": "hm",
      "name": "AI_MasterThesis_Recommendations.ipynb",
      "provenance": [],
      "mount_file_id": "1oLwqD4kIwkhfA4JSXv2yb_2VYFXGEB35",
      "authorship_tag": "ABX9TyOO2ztdDFB1bhaiO4hD45E5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0330da87c948473b800a1407dda1d1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_719d5b433992413f8270ed622964257a",
              "IPY_MODEL_37a16a63da684237b393bb8f5543a1d1",
              "IPY_MODEL_8a72ac040aed421f872d315f3ddacb29"
            ],
            "layout": "IPY_MODEL_09b65840e48743199ad5135c382b2006"
          }
        },
        "719d5b433992413f8270ed622964257a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_136426d3f3ed4c05aa70a27adb2b1528",
            "placeholder": "​",
            "style": "IPY_MODEL_05ce98d6528c48b2893a026bd425b475",
            "value": "Downloading: 100%"
          }
        },
        "37a16a63da684237b393bb8f5543a1d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bbc49de1ccb4c8fa5f18633f1da0e1e",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62b367446c3147178159f7aa7ba84de9",
            "value": 483
          }
        },
        "8a72ac040aed421f872d315f3ddacb29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaa8b296137147d8a5ff53178de02319",
            "placeholder": "​",
            "style": "IPY_MODEL_ccae6e1b35f9412ab7ff868559d13f40",
            "value": " 483/483 [00:00&lt;00:00, 11.3kB/s]"
          }
        },
        "09b65840e48743199ad5135c382b2006": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "136426d3f3ed4c05aa70a27adb2b1528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05ce98d6528c48b2893a026bd425b475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bbc49de1ccb4c8fa5f18633f1da0e1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62b367446c3147178159f7aa7ba84de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eaa8b296137147d8a5ff53178de02319": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccae6e1b35f9412ab7ff868559d13f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd4c7401dd3f40fba0826eb719ab534d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_763bbd89770442e0b78c269f751872ad",
              "IPY_MODEL_aecfaa6d826b474e917201815cbd8efe",
              "IPY_MODEL_5a600ae49c394459ac492e3bf5e655cc"
            ],
            "layout": "IPY_MODEL_3789f09d236249c7a0d361dda35357dd"
          }
        },
        "763bbd89770442e0b78c269f751872ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6d5a01bcde1469db73d3b4b90a6f9e2",
            "placeholder": "​",
            "style": "IPY_MODEL_565ed09e02be40039895258c9d66b81d",
            "value": "Downloading: 100%"
          }
        },
        "aecfaa6d826b474e917201815cbd8efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbcdb36da34c4325946d71706fb2d384",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df1aeb7ecc5849be8eafd0b246804655",
            "value": 231508
          }
        },
        "5a600ae49c394459ac492e3bf5e655cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef2152997a9e4ec899527c6001ed37f1",
            "placeholder": "​",
            "style": "IPY_MODEL_b614433d24d1442db321b8332ec2711a",
            "value": " 226k/226k [00:00&lt;00:00, 897kB/s]"
          }
        },
        "3789f09d236249c7a0d361dda35357dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6d5a01bcde1469db73d3b4b90a6f9e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "565ed09e02be40039895258c9d66b81d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbcdb36da34c4325946d71706fb2d384": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df1aeb7ecc5849be8eafd0b246804655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef2152997a9e4ec899527c6001ed37f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b614433d24d1442db321b8332ec2711a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7fd5ff7fc634b57b9ef4e6ab7e77167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81c1cebfc925417d8b1b4f28fd038c4e",
              "IPY_MODEL_54706146ccf84dcf9a021f6f496d6ba3",
              "IPY_MODEL_881e53cfe4c54a38975143c5b503a5f9"
            ],
            "layout": "IPY_MODEL_39fc78579e314f558ab3e56ac3037780"
          }
        },
        "81c1cebfc925417d8b1b4f28fd038c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30d5131d273e41de9e2ec4bebb6ae16c",
            "placeholder": "​",
            "style": "IPY_MODEL_4b2ad41d13064de788e46fa9fdd4c8a8",
            "value": "Downloading: 100%"
          }
        },
        "54706146ccf84dcf9a021f6f496d6ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_098ef4d0c9fe4c99b049a87c4aebc3ee",
            "max": 285,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b642d1c7fde49cda0830cdc0c49ab11",
            "value": 285
          }
        },
        "881e53cfe4c54a38975143c5b503a5f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67c2894875b74de0ab2b6cb57db572c5",
            "placeholder": "​",
            "style": "IPY_MODEL_0cddc68edeb243299b1755bfddb0d087",
            "value": " 285/285 [00:00&lt;00:00, 8.22kB/s]"
          }
        },
        "39fc78579e314f558ab3e56ac3037780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30d5131d273e41de9e2ec4bebb6ae16c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b2ad41d13064de788e46fa9fdd4c8a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "098ef4d0c9fe4c99b049a87c4aebc3ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b642d1c7fde49cda0830cdc0c49ab11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67c2894875b74de0ab2b6cb57db572c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cddc68edeb243299b1755bfddb0d087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c062f017da604a2c852480accb04b0f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26ac7a56d78a4278b3a336b09d72aafb",
              "IPY_MODEL_0744edaff75e4576b8ccdc102ddcf295",
              "IPY_MODEL_1d10146f753c48b9b8d027b8fc62a8a7"
            ],
            "layout": "IPY_MODEL_dce823bcfa3148b8a28b76e30c46d912"
          }
        },
        "26ac7a56d78a4278b3a336b09d72aafb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c954ae848359400e955fd3c22da876b9",
            "placeholder": "​",
            "style": "IPY_MODEL_181a5a046a714edcaf9cc8a2be4fdee0",
            "value": "Downloading: 100%"
          }
        },
        "0744edaff75e4576b8ccdc102ddcf295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26711ad4fc1042db806ff6e505a8105f",
            "max": 17756393,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e750aa308c884e41bd5a37ef1ec99267",
            "value": 17756393
          }
        },
        "1d10146f753c48b9b8d027b8fc62a8a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89f2bbf22fdf476faab98a11f8c4c960",
            "placeholder": "​",
            "style": "IPY_MODEL_7a389080ff684c69bae01324e01117fc",
            "value": " 16.9M/16.9M [00:00&lt;00:00, 42.2MB/s]"
          }
        },
        "dce823bcfa3148b8a28b76e30c46d912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c954ae848359400e955fd3c22da876b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "181a5a046a714edcaf9cc8a2be4fdee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26711ad4fc1042db806ff6e505a8105f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e750aa308c884e41bd5a37ef1ec99267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89f2bbf22fdf476faab98a11f8c4c960": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a389080ff684c69bae01324e01117fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}